"""
BOM ì›ê°€ ê³„ì‚°ê¸° - ìë™í™” ë²„ì „
SharePoint BOM ë°ì´í„° ìë™ ë¡œë”© + êµ¬ë§¤ ë°ì´í„° ì—…ë¡œë“œë§Œìœ¼ë¡œ ì¦‰ì‹œ ê³„ì‚°
"""

import streamlit as st
import pandas as pd
import numpy as np
import io
import requests
import json
from typing import Dict, Optional, Tuple
from datetime import datetime
import time
import warnings

# ê²½ê³  í•„í„°ë§
warnings.filterwarnings('ignore')

# ì„ íƒì  import (ì—†ì–´ë„ ë™ì‘)
try:
    from tqdm import stqdm
    HAS_PROGRESS = True
except ImportError:
    HAS_PROGRESS = False

try:
    import plotly.express as px
    HAS_PLOTLY = True
except ImportError:
    HAS_PLOTLY = False

class Config:
    """ì„¤ì • í´ë˜ìŠ¤"""
    MAX_FILE_SIZE_MB = 100
    REQUIRED_BOM_COLS = ['ìƒì‚°í’ˆëª©ì½”ë“œ', 'ìƒì‚°í’ˆëª©ëª…', 'ì†Œëª¨í’ˆëª©ì½”ë“œ', 'ì†Œëª¨í’ˆëª©ëª…', 'ì†Œìš”ëŸ‰']
    TEST_ITEM_CODE = '99701'

class SharePointClient:
    """SharePoint ìë™ ì—°ë™ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.access_token = None
        self.token_expires_at = 0
        
    def get_access_token(self) -> Optional[str]:
        """Azure AD í† í° íšë“ (ìë™, ë¬´ì¶œë ¥)"""
        try:
            # Streamlit secretsì—ì„œ ì„¤ì • ì½ê¸°
            tenant_id = st.secrets["sharepoint"]["tenant_id"]
            client_id = st.secrets["sharepoint"]["client_id"]
            client_secret = st.secrets["sharepoint"]["client_secret"]
            
            # í† í°ì´ ìœ íš¨í•œì§€ í™•ì¸ (5ë¶„ ì—¬ìœ )
            if self.access_token and time.time() < self.token_expires_at - 300:
                return self.access_token
            
            # ìƒˆ í† í° ìš”ì²­
            token_url = f"https://login.microsoftonline.com/{tenant_id}/oauth2/v2.0/token"
            
            token_data = {
                'grant_type': 'client_credentials',
                'client_id': client_id,
                'client_secret': client_secret,
                'scope': 'https://graph.microsoft.com/.default'
            }
            
            response = requests.post(token_url, data=token_data)
            response.raise_for_status()
            
            token_info = response.json()
            self.access_token = token_info['access_token']
            self.token_expires_at = time.time() + token_info.get('expires_in', 3600)
            
            return self.access_token
            
        except Exception:
            return None
    
    def get_site_id(self, site_name: str) -> Optional[str]:
        """ì‚¬ì´íŠ¸ ID íšë“ (ìë™, ë¬´ì¶œë ¥)"""
        try:
            token = self.get_access_token()
            if not token:
                return None
            
            headers = {
                'Authorization': f'Bearer {token}',
                'Accept': 'application/json'
            }
            
            site_url = f"https://graph.microsoft.com/v1.0/sites/goremi.sharepoint.com:/sites/{site_name}"
            response = requests.get(site_url, headers=headers)
            response.raise_for_status()
            
            site_info = response.json()
            return site_info['id']
            
        except Exception:
            return None
    
    def auto_download_bom_data(self) -> Optional[bytes]:
        """BOM ë°ì´í„° ìë™ ë‹¤ìš´ë¡œë“œ (ë°±ê·¸ë¼ìš´ë“œ)"""
        try:
            token = self.get_access_token()
            if not token:
                return None
            
            site_name = st.secrets["sharepoint_files"]["site_name"]
            file_name = st.secrets["sharepoint_files"]["file_name"]
            
            site_id = self.get_site_id(site_name)
            if not site_id:
                return None
            
            headers = {
                'Authorization': f'Bearer {token}',
                'Accept': 'application/json'
            }
            
            # ë“œë¼ì´ë¸Œ ì¡°íšŒ
            drives_url = f"https://graph.microsoft.com/v1.0/sites/{site_id}/drives"
            drives_response = requests.get(drives_url, headers=headers)
            drives_response.raise_for_status()
            
            drives = drives_response.json()['value']
            if not drives:
                return None
            
            file_item = None
            drive_id = None
            
            # ëª¨ë“  ë“œë¼ì´ë¸Œì—ì„œ íŒŒì¼ ê²€ìƒ‰
            for drive in drives:
                try:
                    drive_id = drive['id']
                    
                    # ê²€ìƒ‰ API ì‚¬ìš©
                    search_url = f"https://graph.microsoft.com/v1.0/drives/{drive_id}/root/search(q='{file_name}')"
                    search_response = requests.get(search_url, headers=headers)
                    
                    if search_response.status_code == 200:
                        search_results = search_response.json().get('value', [])
                        if search_results:
                            file_item = search_results[0]
                            break
                    
                    # ë£¨íŠ¸ ë””ë ‰í„°ë¦¬ ì§ì ‘ ì¡°íšŒ
                    if not file_item:
                        root_url = f"https://graph.microsoft.com/v1.0/drives/{drive_id}/root/children"
                        root_response = requests.get(root_url, headers=headers)
                        
                        if root_response.status_code == 200:
                            root_files = root_response.json().get('value', [])
                            for f in root_files:
                                if f['name'].lower() == file_name.lower():
                                    file_item = f
                                    break
                    
                    if file_item:
                        break
                        
                except Exception:
                    continue
            
            if not file_item:
                return None
            
            # ë‹¤ìš´ë¡œë“œ URL ìƒì„±
            download_url = None
            
            if '@microsoft.graph.downloadUrl' in file_item:
                download_url = file_item['@microsoft.graph.downloadUrl']
            elif 'id' in file_item:
                download_url = f"https://graph.microsoft.com/v1.0/drives/{drive_id}/items/{file_item['id']}/content"
            else:
                download_url = f"https://graph.microsoft.com/v1.0/drives/{drive_id}/root:/{file_name}:/content"
            
            if not download_url:
                return None
            
            # íŒŒì¼ ë‹¤ìš´ë¡œë“œ
            if 'graph.microsoft.com' in download_url and '/content' in download_url:
                download_headers = headers.copy()
            else:
                download_headers = {}
            
            file_response = requests.get(download_url, headers=download_headers)
            file_response.raise_for_status()
            
            if len(file_response.content) == 0:
                return None
            
            return file_response.content
            
        except Exception:
            return None

def validate_file_size(file_content: bytes, max_mb: int = 100) -> bool:
    """íŒŒì¼ í¬ê¸° ê²€ì¦"""
    try:
        size_mb = len(file_content) / (1024 * 1024)
        return size_mb <= max_mb
    except Exception:
        return False

def safe_load_data(file_content: bytes, file_name: str, skiprows: int = 0) -> Optional[pd.DataFrame]:
    """ì•ˆì „í•œ íŒŒì¼ ë¡œë”©"""
    try:
        file_obj = io.BytesIO(file_content)
        
        # íŒŒì¼ í˜•ì‹ë³„ ë¡œë”©
        if file_name.lower().endswith('.csv'):
            # CSV ì¸ì½”ë”© ì‹œë„
            for encoding in ['utf-8-sig', 'utf-8', 'cp949', 'euc-kr']:
                try:
                    file_obj.seek(0)
                    df = pd.read_csv(file_obj, skiprows=skiprows, encoding=encoding, dtype=str)
                    break
                except:
                    continue
            else:
                return None
                
        elif file_name.lower().endswith(('.xlsx', '.xls')):
            df = pd.read_excel(file_obj, skiprows=skiprows, dtype=str)
        else:
            return None
        
        # í—¤ë” ë¬¸ì œ í•´ê²° (êµ¬ë§¤ ë°ì´í„°ìš©)
        if 'purchase' in file_name.lower() or any('Unnamed:' in str(col) for col in df.columns):
            df = fix_purchase_data_headers(df)
        
        # ë°ì´í„° ì •ì œ
        for col in df.select_dtypes(include=['object']).columns:
            df[col] = df[col].astype(str).str.strip()
        
        # ë¹ˆ í–‰/ì—´ ì œê±°
        df = df.dropna(how='all').dropna(axis=1, how='all')
        
        return df if not df.empty else None
        
    except Exception:
        return None

def fix_purchase_data_headers(df: pd.DataFrame) -> pd.DataFrame:
    """êµ¬ë§¤ ë°ì´í„° í—¤ë” ë¬¸ì œ í•´ê²°"""
    try:
        # ì²« ë²ˆì§¸ í–‰ì—ì„œ ì‹¤ì œ í—¤ë” ì°¾ê¸°
        potential_headers = None
        
        # 0í–‰ë¶€í„° 3í–‰ê¹Œì§€ í—¤ë” í›„ë³´ ê²€ìƒ‰
        for i in range(min(4, len(df))):
            row_values = df.iloc[i].fillna('').astype(str).tolist()
            row_text = ' '.join(row_values)
            
            # í—¤ë”ì˜ íŠ¹ì§•ì ì¸ í‚¤ì›Œë“œë“¤ í™•ì¸
            header_keywords = ['ì¼ì', 'í’ˆëª©ì½”ë“œ', 'í’ˆëª©ëª…', 'ë‹¨ê°€', 'ìˆ˜ëŸ‰', 'ê±°ë˜ì²˜']
            keyword_count = sum(1 for keyword in header_keywords if keyword in row_text)
            
            if keyword_count >= 3:  # 3ê°œ ì´ìƒì˜ í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ í—¤ë”ë¡œ íŒë‹¨
                potential_headers = row_values
                header_row_idx = i
                break
        
        if potential_headers:
            # í—¤ë” ì •ë¦¬ ë° ì ìš©
            cleaned_headers = []
            for header in potential_headers:
                # í—¤ë”ëª… ì •ë¦¬
                header = str(header).strip()
                if header in ['', 'nan', 'None']:
                    header = f"ì»¬ëŸ¼_{len(cleaned_headers)+1}"
                
                cleaned_headers.append(header)
            
            # ìƒˆë¡œìš´ DataFrame ìƒì„±
            new_df = df.iloc[header_row_idx + 1:].copy()
            new_df.columns = cleaned_headers[:len(new_df.columns)]
            new_df = new_df.reset_index(drop=True)
            
            # ë¹ˆ í–‰ ì œê±°
            new_df = new_df.dropna(how='all')
            
            return new_df
        
        else:
            return df
        
    except Exception:
        return df

def validate_bom_data(df: pd.DataFrame) -> Tuple[bool, str]:
    """BOM ë°ì´í„° ê°„ë‹¨ ê²€ì¦"""
    try:
        # í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸
        missing_cols = [col for col in Config.REQUIRED_BOM_COLS if col not in df.columns]
        if missing_cols:
            return False, f"í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: {missing_cols}"
        
        # ë°ì´í„° ì¡´ì¬ í™•ì¸
        if df.empty:
            return False, "ë°ì´í„°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤"
        
        return True, "ê²€ì¦ í†µê³¼"
        
    except Exception as e:
        return False, f"ê²€ì¦ ì˜¤ë¥˜: {e}"

def extract_purchase_prices(df: pd.DataFrame) -> Dict[str, float]:
    """êµ¬ë§¤ ë°ì´í„°ì—ì„œ ë‹¨ê°€ ì¶”ì¶œ (ìë™ ê°ì§€)"""
    try:
        if df.empty:
            return {}
        
        # ì»¬ëŸ¼ ìë™ ê°ì§€
        date_col, item_col, price_col = None, None, None
        
        # ê° ì»¬ëŸ¼ëª…ì„ ë¶„ì„í•˜ì—¬ ë§¤ì¹­
        for col in df.columns:
            col_str = str(col).lower()
            
            # ì¼ì ì»¬ëŸ¼ ê°ì§€
            if not date_col:
                if any(keyword in col_str for keyword in ['ì¼ì', 'date', 'ë‚ ì§œ']) or 'ì¼ì-no' in col_str:
                    date_col = col
            
            # í’ˆëª©ì½”ë“œ ì»¬ëŸ¼ ê°ì§€  
            if not item_col:
                if 'í’ˆëª©ì½”ë“œ' in col_str:
                    item_col = col
            
            # ë‹¨ê°€ ì»¬ëŸ¼ ê°ì§€
            if not price_col:
                if 'ë‹¨ê°€' in col_str and 'ê³µê¸‰' not in col_str and 'ì´' not in col_str:
                    price_col = col
        
        # ì»¬ëŸ¼ì„ ì°¾ì§€ ëª»í•œ ê²½ìš° ì¸ë±ìŠ¤ë¡œ ëŒ€ì²´
        if not date_col and len(df.columns) > 0:
            date_col = df.columns[0]
            
        if not item_col and len(df.columns) > 1:
            item_col = df.columns[1]
            
        if not price_col:
            # ë‹¨ê°€ ê´€ë ¨ ì»¬ëŸ¼ ìš°ì„  íƒìƒ‰
            for i, col in enumerate(df.columns):
                if i >= 3:  # 3ë²ˆì§¸ ì»¬ëŸ¼ë¶€í„°
                    sample_value = str(df[col].dropna().iloc[0] if not df[col].dropna().empty else '')
                    # ìˆ«ìë¡œ ë³€í™˜ ê°€ëŠ¥í•œ ì»¬ëŸ¼ ì°¾ê¸°
                    try:
                        float(sample_value.replace(',', ''))
                        price_col = col
                        break
                    except:
                        continue
            
            # ê·¸ë˜ë„ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’
            if not price_col and len(df.columns) > 5:
                price_col = df.columns[5]
        
        if not all([date_col, item_col, price_col]):
            return {}
        
        # ë°ì´í„° ì •ì œ
        work_df = df[[date_col, item_col, price_col]].copy()
        work_df.columns = ['date', 'item_code', 'price']
        
        # ë¹ˆê°’ ì œê±°
        work_df = work_df.dropna()
        
        # íƒ€ì… ë³€í™˜
        work_df['item_code'] = work_df['item_code'].astype(str).str.strip()
        work_df['price'] = pd.to_numeric(work_df['price'], errors='coerce')
        
        # ìœ íš¨í•œ ë°ì´í„°ë§Œ
        work_df = work_df[
            (work_df['item_code'] != '') & 
            (work_df['item_code'] != 'nan') &
            (work_df['price'] > 0) & 
            (work_df['price'].notna())
        ]
        
        if work_df.empty:
            return {}
        
        # ë‚ ì§œ ì²˜ë¦¬ (ê°„ë‹¨í•˜ê²Œ)
        try:
            work_df['date_str'] = work_df['date'].astype(str).str.split('-').str[0]
            work_df['date_parsed'] = pd.to_datetime(work_df['date_str'], errors='coerce')
            work_df = work_df.dropna(subset=['date_parsed'])
            work_df = work_df.sort_values('date_parsed', ascending=False)
        except:
            pass
        
        # ìµœì‹  ë‹¨ê°€ ì¶”ì¶œ
        latest_prices = work_df.drop_duplicates(subset='item_code', keep='first')
        
        # ë”•ì…”ë„ˆë¦¬ ë³€í™˜
        price_dict = {}
        for _, row in latest_prices.iterrows():
            code = row['item_code']
            price = row['price']
            if pd.notna(price) and price > 0:
                price_dict[code] = float(price)
        
        return price_dict
        
    except Exception:
        return {}

def clean_bom_data(df: pd.DataFrame) -> pd.DataFrame:
    """BOM ë°ì´í„° ì •ì œ"""
    try:
        clean_df = df.copy()
        
        # í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸
        missing_cols = [col for col in Config.REQUIRED_BOM_COLS if col not in clean_df.columns]
        if missing_cols:
            return pd.DataFrame()
        
        # ë°ì´í„° ì •ì œ
        clean_df['ìƒì‚°í’ˆëª©ì½”ë“œ'] = clean_df['ìƒì‚°í’ˆëª©ì½”ë“œ'].astype(str).str.strip()
        clean_df['ì†Œëª¨í’ˆëª©ì½”ë“œ'] = clean_df['ì†Œëª¨í’ˆëª©ì½”ë“œ'].astype(str).str.strip()
        clean_df['ì†Œìš”ëŸ‰'] = pd.to_numeric(clean_df['ì†Œìš”ëŸ‰'], errors='coerce').fillna(0.0)
        
        # test í’ˆëª© ì œê±°
        clean_df = clean_df[clean_df['ì†Œëª¨í’ˆëª©ì½”ë“œ'] != Config.TEST_ITEM_CODE]
        
        # ìœ íš¨í•˜ì§€ ì•Šì€ ë°ì´í„° ì œê±°
        clean_df = clean_df[
            (clean_df['ìƒì‚°í’ˆëª©ì½”ë“œ'] != '') &
            (clean_df['ì†Œëª¨í’ˆëª©ì½”ë“œ'] != '') &
            (clean_df['ìƒì‚°í’ˆëª©ì½”ë“œ'] != 'nan') &
            (clean_df['ì†Œëª¨í’ˆëª©ì½”ë“œ'] != 'nan') &
            (clean_df['ì†Œìš”ëŸ‰'] >= 0)
        ]
        
        return clean_df
        
    except Exception:
        return pd.DataFrame()

def calculate_product_cost_with_reason(product_code: str, bom_df: pd.DataFrame, all_costs: Dict[str, float], cache: Dict[str, float]) -> Tuple[float, str]:
    """ë‹¨ì¼ ì œí’ˆ ì›ê°€ ê³„ì‚° + ì‹¤íŒ¨ ì´ìœ  ë¶„ì„"""
    try:
        # ìºì‹œ í™•ì¸
        if product_code in cache:
            return cache[product_code], ""
        
        # BOM êµ¬ì„±ìš”ì†Œ ê°€ì ¸ì˜¤ê¸°
        components = bom_df[bom_df['ìƒì‚°í’ˆëª©ì½”ë“œ'] == product_code]
        
        if components.empty:
            cache[product_code] = 0.0
            return 0.0, "BOM êµ¬ì„±ìš”ì†Œ ì—†ìŒ"
        
        total_cost = 0.0
        missing_components = []
        zero_price_components = []
        invalid_quantity_components = []
        
        for _, comp in components.iterrows():
            comp_code = comp['ì†Œëª¨í’ˆëª©ì½”ë“œ']
            comp_name = comp['ì†Œëª¨í’ˆëª©ëª…']
            quantity = float(comp['ì†Œìš”ëŸ‰'])
            
            # ìˆ˜ëŸ‰ ê²€ì¦
            if quantity <= 0:
                invalid_quantity_components.append(f"{comp_name}({comp_code})")
                continue
            
            # ë¶€í’ˆ ë‹¨ê°€ ì°¾ê¸°
            if comp_code in all_costs:
                unit_price = all_costs[comp_code]
                if unit_price <= 0:
                    zero_price_components.append(f"{comp_name}({comp_code})")
                    continue
            elif comp_code in bom_df['ìƒì‚°í’ˆëª©ì½”ë“œ'].values:
                # ì¬ê·€ ê³„ì‚°
                unit_price, _ = calculate_product_cost_with_reason(comp_code, bom_df, all_costs, cache)
                if unit_price <= 0:
                    missing_components.append(f"{comp_name}({comp_code})")
                    continue
                all_costs[comp_code] = unit_price
            else:
                missing_components.append(f"{comp_name}({comp_code})")
                continue
            
            total_cost += quantity * unit_price
        
        cache[product_code] = total_cost
        
        # ì‹¤íŒ¨ ì´ìœ  ë¶„ì„
        if total_cost == 0:
            reasons = []
            if missing_components:
                reasons.append(f"ë‹¨ê°€ì •ë³´ ì—†ìŒ: {', '.join(missing_components[:3])}{'...' if len(missing_components) > 3 else ''}")
            if zero_price_components:
                reasons.append(f"ë‹¨ê°€ 0ì›: {', '.join(zero_price_components[:3])}{'...' if len(zero_price_components) > 3 else ''}")
            if invalid_quantity_components:
                reasons.append(f"ìˆ˜ëŸ‰ ì˜¤ë¥˜: {', '.join(invalid_quantity_components[:3])}{'...' if len(invalid_quantity_components) > 3 else ''}")
            
            failure_reason = " | ".join(reasons) if reasons else "ì•Œ ìˆ˜ ì—†ëŠ” ì´ìœ "
            return 0.0, failure_reason
        
        return total_cost, ""
        
    except Exception as e:
        return 0.0, f"ê³„ì‚° ì˜¤ë¥˜: {str(e)}"

def calculate_all_bom_costs(bom_df: pd.DataFrame, purchase_prices: Dict[str, float]) -> Tuple[pd.DataFrame, pd.DataFrame]:
    """ì „ì²´ BOM ì›ê°€ ê³„ì‚°"""
    try:
        start_time = time.time()
        
        # ë°ì´í„° ì •ì œ
        clean_bom = clean_bom_data(bom_df)
        
        if clean_bom.empty:
            return pd.DataFrame(), pd.DataFrame()
        
        # ëª¨ë“  ìƒì‚°í’ˆëª©
        all_products = clean_bom[['ìƒì‚°í’ˆëª©ì½”ë“œ', 'ìƒì‚°í’ˆëª©ëª…']].drop_duplicates().reset_index(drop=True)
        
        # ì „ì²´ ì›ê°€ ë”•ì…”ë„ˆë¦¬
        all_costs = purchase_prices.copy()
        calc_cache = {}
        failure_reasons = {}
        
        # ê³„ì‚° ì‹¤í–‰
        results = []
        
        if HAS_PROGRESS:
            iterator = stqdm(all_products.iterrows(), total=len(all_products), desc="BOM ì›ê°€ ê³„ì‚°")
        else:
            iterator = all_products.iterrows()
            progress_bar = st.progress(0)
        
        for idx, (_, product) in enumerate(iterator):
            product_code = product['ìƒì‚°í’ˆëª©ì½”ë“œ']
            product_name = product['ìƒì‚°í’ˆëª©ëª…']
            
            # ì›ê°€ ê³„ì‚°
            calculated_cost, failure_reason = calculate_product_cost_with_reason(
                product_code, clean_bom, all_costs, calc_cache
            )
            
            if calculated_cost == 0 and failure_reason:
                failure_reasons[product_code] = failure_reason
            
            results.append({
                'ìƒì‚°í’ˆëª©ì½”ë“œ': product_code,
                'ìƒì‚°í’ˆëª©ëª…': product_name,
                'ê³„ì‚°ëœë‹¨ìœ„ì›ê°€': calculated_cost,
                'ê³„ì‚°ìƒíƒœ': 'ê³„ì‚°ì™„ë£Œ' if calculated_cost > 0 else 'ê³„ì‚°ë¶ˆê°€',
                'ì‹¤íŒ¨ì´ìœ ': failure_reasons.get(product_code, '')
            })
            
            # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
            if not HAS_PROGRESS:
                progress_bar.progress((idx + 1) / len(all_products))
        
        if not HAS_PROGRESS:
            progress_bar.empty()
        
        # ê²°ê³¼ DataFrame
        result_df = pd.DataFrame(results)
        
        # ìƒì„¸ ë‚´ì—­
        details_df = clean_bom.copy()
        details_df['ë¶€í’ˆë‹¨ê°€'] = details_df['ì†Œëª¨í’ˆëª©ì½”ë“œ'].apply(lambda x: all_costs.get(x, 0.0))
        details_df['ë¶€í’ˆë³„ì›ê°€'] = details_df['ì†Œìš”ëŸ‰'] * details_df['ë¶€í’ˆë‹¨ê°€']
        
        return result_df, details_df
        
    except Exception:
        return pd.DataFrame(), pd.DataFrame()

def create_simple_chart(df: pd.DataFrame) -> None:
    """ê°„ë‹¨í•œ ì°¨íŠ¸ ìƒì„±"""
    if not HAS_PLOTLY or df.empty:
        return
    
    try:
        # ê³„ì‚°ëœ ì™„ì œí’ˆë§Œ
        chart_data = df[df['ê³„ì‚°ëœë‹¨ìœ„ì›ê°€'] > 0]
        
        if len(chart_data) < 5:
            return
        
        # ìƒìœ„ 20ê°œ ì œí’ˆ ë°”ì°¨íŠ¸
        top_items = chart_data.nlargest(20, 'ê³„ì‚°ëœë‹¨ìœ„ì›ê°€')
        
        fig = px.bar(
            top_items,
            x='ê³„ì‚°ëœë‹¨ìœ„ì›ê°€',
            y='ìƒì‚°í’ˆëª©ì½”ë“œ',
            orientation='h',
            title='ì›ê°€ ìƒìœ„ 20ê°œ ì™„ì œí’ˆ',
            labels={'ê³„ì‚°ëœë‹¨ìœ„ì›ê°€': 'ì›ê°€ (ì›)', 'ìƒì‚°í’ˆëª©ì½”ë“œ': 'ì œí’ˆì½”ë“œ'}
        )
        fig.update_layout(height=500, yaxis={'categoryorder': 'total ascending'})
        st.plotly_chart(fig, use_container_width=True)
        
    except Exception:
        pass

def export_to_excel(finished_goods: pd.DataFrame, all_results: pd.DataFrame, details: pd.DataFrame) -> bytes:
    """ì—‘ì…€ ë‚´ë³´ë‚´ê¸°"""
    try:
        output = io.BytesIO()
        
        with pd.ExcelWriter(output, engine='openpyxl') as writer:
            # ì™„ì œí’ˆ ì›ê°€ ì‹œíŠ¸
            finished_display = finished_goods.copy()
            
            if 'ì‹¤íŒ¨ì´ìœ ' in finished_display.columns:
                finished_display = finished_display[['ìƒì‚°í’ˆëª©ì½”ë“œ', 'ìƒì‚°í’ˆëª©ëª…', 'ê³„ì‚°ëœë‹¨ìœ„ì›ê°€', 'ê³„ì‚°ìƒíƒœ', 'ì‹¤íŒ¨ì´ìœ ']]
                finished_display.columns = ['í’ˆëª©ì½”ë“œ', 'í’ˆëª©ëª…', 'ë‹¨ìœ„ì›ê°€(ì›)', 'ê³„ì‚°ìƒíƒœ', 'ì‹¤íŒ¨ì´ìœ ']
            else:
                finished_display = finished_display[['ìƒì‚°í’ˆëª©ì½”ë“œ', 'ìƒì‚°í’ˆëª©ëª…', 'ê³„ì‚°ëœë‹¨ìœ„ì›ê°€', 'ê³„ì‚°ìƒíƒœ']]
                finished_display.columns = ['í’ˆëª©ì½”ë“œ', 'í’ˆëª©ëª…', 'ë‹¨ìœ„ì›ê°€(ì›)', 'ê³„ì‚°ìƒíƒœ']
            
            finished_display.to_excel(writer, sheet_name='ì™„ì œí’ˆì›ê°€', index=False)
            
            # ì „ì²´ ì œí’ˆ ì›ê°€ ì‹œíŠ¸
            all_display = all_results.copy()
            if 'ì‹¤íŒ¨ì´ìœ ' in all_display.columns:
                all_display = all_display[['ìƒì‚°í’ˆëª©ì½”ë“œ', 'ìƒì‚°í’ˆëª©ëª…', 'ê³„ì‚°ëœë‹¨ìœ„ì›ê°€', 'ê³„ì‚°ìƒíƒœ', 'ì‹¤íŒ¨ì´ìœ ']]
                all_display.columns = ['í’ˆëª©ì½”ë“œ', 'í’ˆëª©ëª…', 'ë‹¨ìœ„ì›ê°€(ì›)', 'ê³„ì‚°ìƒíƒœ', 'ì‹¤íŒ¨ì´ìœ ']
            
            all_display.to_excel(writer, sheet_name='ì „ì²´ì œí’ˆì›ê°€', index=False)
            
            # ìƒì„¸ ë‚´ì—­ ì‹œíŠ¸
            details_display = details.copy()
            details_cols = ['ìƒì‚°í’ˆëª©ì½”ë“œ', 'ìƒì‚°í’ˆëª©ëª…', 'ì†Œëª¨í’ˆëª©ì½”ë“œ', 'ì†Œëª¨í’ˆëª©ëª…', 'ì†Œìš”ëŸ‰', 'ë¶€í’ˆë‹¨ê°€', 'ë¶€í’ˆë³„ì›ê°€']
            details_display = details_display[details_cols]
            details_display.columns = ['ìƒì‚°í’ˆëª©ì½”ë“œ', 'ìƒì‚°í’ˆëª©ëª…', 'ë¶€í’ˆì½”ë“œ', 'ë¶€í’ˆëª…', 'ì†Œìš”ëŸ‰', 'ë¶€í’ˆë‹¨ê°€(ì›)', 'ë¶€í’ˆì›ê°€(ì›)']
            
            details_display.to_excel(writer, sheet_name='ìƒì„¸ë‚´ì—­', index=False)
        
        return output.getvalue()
        
    except Exception:
        return b''

def main():
    """ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜ - ì™„ì „ ìë™í™”"""
    
    st.set_page_config(
        page_title="BOM ì›ê°€ ê³„ì‚°ê¸°",
        page_icon="ğŸ­",
        layout="wide"
    )
    
    st.title("ğŸ­ BOM ì›ê°€ ê³„ì‚°ê¸°")
    st.markdown("**ğŸš€ SharePoint ìë™ ì—°ë™ + êµ¬ë§¤ ë°ì´í„°ë§Œ ì—…ë¡œë“œí•˜ë©´ ì¦‰ì‹œ ê³„ì‚°!**")
    
    # SharePoint í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ë° ìë™ BOM ë¡œë”©
    sharepoint_client = SharePointClient()
    
    # ì„¸ì…˜ ìƒíƒœì— BOM ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ìë™ ë¡œë”©
    if 'auto_bom_data' not in st.session_state:
        with st.spinner("ğŸ”„ SharePointì—ì„œ BOM ë°ì´í„° ìë™ ë¡œë”© ì¤‘..."):
            bom_content = sharepoint_client.auto_download_bom_data()
            
            if bom_content and validate_file_size(bom_content):
                bom_df = safe_load_data(bom_content, st.secrets["sharepoint_files"]["file_name"], skiprows=1)
                
                if bom_df is not None:
                    bom_valid, _ = validate_bom_data(bom_df)
                    
                    if bom_valid:
                        st.session_state['auto_bom_data'] = bom_df
                        st.success("âœ… SharePoint BOM ë°ì´í„° ìë™ ë¡œë”© ì™„ë£Œ!")
                    else:
                        st.error("âŒ SharePoint BOM ë°ì´í„° ê²€ì¦ ì‹¤íŒ¨")
                else:
                    st.error("âŒ SharePoint BOM ë°ì´í„° íŒŒì‹± ì‹¤íŒ¨")
            else:
                st.error("âŒ SharePoint ì—°ê²° ì‹¤íŒ¨ - ìˆ˜ë™ìœ¼ë¡œ BOM íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”")
    
    # BOM ë°ì´í„° ìƒíƒœ í‘œì‹œ
    if 'auto_bom_data' in st.session_state:
        bom_df = st.session_state['auto_bom_data']
        clean_bom = clean_bom_data(bom_df.copy())
        
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("ğŸ“‹ BOM ë°ì´í„°", "âœ… ë¡œë”©ì™„ë£Œ")
        with col2:
            st.metric("ğŸ­ ìƒì‚°í’ˆëª©", f"{clean_bom['ìƒì‚°í’ˆëª©ì½”ë“œ'].nunique():,}ê°œ")
        with col3:
            st.metric("ğŸ§© ì†Œëª¨í’ˆëª©", f"{clean_bom['ì†Œëª¨í’ˆëª©ì½”ë“œ'].nunique():,}ê°œ")
        
        # êµ¬ë§¤ ë°ì´í„° ì—…ë¡œë“œ
        st.header("ğŸ“¥ êµ¬ë§¤ ë°ì´í„° ì—…ë¡œë“œ")
        
        purchase_file = st.file_uploader(
            "ğŸ’° êµ¬ë§¤ ë°ì´í„° íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš” (CSV, Excel)", 
            type=['csv', 'xlsx', 'xls'],
            help="êµ¬ë§¤ ë°ì´í„° íŒŒì¼ì„ ì—…ë¡œë“œí•˜ë©´ ìë™ìœ¼ë¡œ BOM ì›ê°€ ê³„ì‚°ì´ ì‹œì‘ë©ë‹ˆë‹¤."
        )
        
        if purchase_file:
            # ìë™ ê³„ì‚° ì‹œì‘
            with st.spinner("ğŸ”„ êµ¬ë§¤ ë°ì´í„° ì²˜ë¦¬ ë° BOM ì›ê°€ ê³„ì‚° ì¤‘..."):
                
                # êµ¬ë§¤ ë°ì´í„° ë¡œë”©
                purchase_df = safe_load_data(purchase_file.getvalue(), purchase_file.name)
                
                if purchase_df is not None:
                    # êµ¬ë§¤ ë‹¨ê°€ ì¶”ì¶œ
                    purchase_prices = extract_purchase_prices(purchase_df)
                    
                    if purchase_prices:
                        # BOM ì›ê°€ ê³„ì‚°
                        result_df, details_df = calculate_all_bom_costs(bom_df, purchase_prices)
                        
                        if not result_df.empty:
                            # ì™„ì œí’ˆ í•„í„°ë§
                            finished_goods = result_df[
                                result_df['ìƒì‚°í’ˆëª©ëª…'].str.contains('[ì™„ì œí’ˆ]', regex=False, na=False)
                            ].copy()
                            
                            # ê³„ì‚° ì™„ë£Œ ì•Œë¦¼
                            st.balloons()
                            st.success("ğŸ‰ BOM ì›ê°€ ê³„ì‚° ì™„ë£Œ!")
                            
                            # ê²°ê³¼ í‘œì‹œ
                            st.header("ğŸ¯ ê³„ì‚° ê²°ê³¼")
                            
                            # í†µê³„
                            total = len(finished_goods)
                            calculated = len(finished_goods[finished_goods['ê³„ì‚°ìƒíƒœ'] == 'ê³„ì‚°ì™„ë£Œ'])
                            success_rate = (calculated / total * 100) if total > 0 else 0
                            
                            col1, col2, col3, col4 = st.columns(4)
                            with col1:
                                st.metric("ğŸ¯ ì™„ì œí’ˆ", f"{total:,}ê°œ")
                            with col2:
                                st.metric("âœ… ê³„ì‚°ì„±ê³µ", f"{calculated:,}ê°œ") 
                            with col3:
                                st.metric("ğŸ“Š ì„±ê³µë¥ ", f"{success_rate:.1f}%")
                            with col4:
                                st.metric("ğŸ’° êµ¬ë§¤ë‹¨ê°€", f"{len(purchase_prices):,}ê°œ")
                            
                            # ê²°ê³¼ í…Œì´ë¸”
                            if not finished_goods.empty:
                                # ì‹¤íŒ¨ ì´ìœ  í¬í•¨í•œ ì»¬ëŸ¼ êµ¬ì„±
                                if 'ì‹¤íŒ¨ì´ìœ ' in finished_goods.columns:
                                    display_df = finished_goods[['ìƒì‚°í’ˆëª©ì½”ë“œ', 'ìƒì‚°í’ˆëª©ëª…', 'ê³„ì‚°ëœë‹¨ìœ„ì›ê°€', 'ê³„ì‚°ìƒíƒœ', 'ì‹¤íŒ¨ì´ìœ ']].copy()
                                    display_df.columns = ['í’ˆëª©ì½”ë“œ', 'í’ˆëª©ëª…', 'ë‹¨ìœ„ì›ê°€(ì›)', 'ìƒíƒœ', 'ì‹¤íŒ¨ì´ìœ ']
                                else:
                                    display_df = finished_goods[['ìƒì‚°í’ˆëª©ì½”ë“œ', 'ìƒì‚°í’ˆëª©ëª…', 'ê³„ì‚°ëœë‹¨ìœ„ì›ê°€', 'ê³„ì‚°ìƒíƒœ']].copy()
                                    display_df.columns = ['í’ˆëª©ì½”ë“œ', 'í’ˆëª©ëª…', 'ë‹¨ìœ„ì›ê°€(ì›)', 'ìƒíƒœ']
                                
                                # ìŠ¤íƒ€ì¼ë§
                                def highlight_rows(row):
                                    if row['ìƒíƒœ'] == 'ê³„ì‚°ì™„ë£Œ':
                                        return ['background-color: #d4edda'] * len(row)
                                    else:
                                        return ['background-color: #f8d7da'] * len(row)
                                
                                styled_df = display_df.style.apply(highlight_rows, axis=1).format({
                                    'ë‹¨ìœ„ì›ê°€(ì›)': '{:,.0f}'
                                })
                                
                                st.dataframe(styled_df, use_container_width=True, height=400)
                                
                                # ì›ê°€ í†µê³„
                                calculated_items = finished_goods[finished_goods['ê³„ì‚°ìƒíƒœ'] == 'ê³„ì‚°ì™„ë£Œ']
                                if not calculated_items.empty:
                                    avg_cost = calculated_items['ê³„ì‚°ëœë‹¨ìœ„ì›ê°€'].mean()
                                    max_cost = calculated_items['ê³„ì‚°ëœë‹¨ìœ„ì›ê°€'].max()
                                    min_cost = calculated_items[calculated_items['ê³„ì‚°ëœë‹¨ìœ„ì›ê°€'] > 0]['ê³„ì‚°ëœë‹¨ìœ„ì›ê°€'].min()
                                    
                                    st.subheader("ğŸ“ˆ ì›ê°€ ë¶„ì„")
                                    col1, col2, col3 = st.columns(3)
                                    
                                    with col1:
                                        st.metric("ğŸ’° í‰ê·  ì›ê°€", f"{avg_cost:,.0f}ì›")
                                    with col2:
                                        st.metric("ğŸ“ˆ ìµœê³  ì›ê°€", f"{max_cost:,.0f}ì›")
                                    with col3:
                                        st.metric("ğŸ“‰ ìµœì € ì›ê°€", f"{min_cost:,.0f}ì›")
                                
                                # ì‹œê°í™”
                                if HAS_PLOTLY:
                                    st.subheader("ğŸ“Š ì›ê°€ ë¶„ì„ ì°¨íŠ¸")
                                    create_simple_chart(calculated_items)
                            
                            # ê²°ê³¼ ë‹¤ìš´ë¡œë“œ
                            st.header("ğŸ“¥ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ")
                            
                            excel_data = export_to_excel(finished_goods, result_df, details_df)
                            
                            if excel_data:
                                st.download_button(
                                    label="ğŸ“Š BOM ì›ê°€ ê³„ì‚° ê²°ê³¼ ë‹¤ìš´ë¡œë“œ (Excel)",
                                    data=excel_data,
                                    file_name=f'BOMì›ê°€ê³„ì‚°_{datetime.now().strftime("%Y%m%d_%H%M")}.xlsx',
                                    mime='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',
                                    use_container_width=True
                                )
                        else:
                            st.error("âŒ BOM ì›ê°€ ê³„ì‚° ì‹¤íŒ¨")
                    else:
                        st.error("âŒ êµ¬ë§¤ ë‹¨ê°€ ì¶”ì¶œ ì‹¤íŒ¨ - êµ¬ë§¤ ë°ì´í„° í˜•ì‹ì„ í™•ì¸í•´ì£¼ì„¸ìš”")
                else:
                    st.error("âŒ êµ¬ë§¤ ë°ì´í„° íŒŒì¼ ë¡œë”© ì‹¤íŒ¨")
    
    else:
        # SharePoint ë¡œë”© ì‹¤íŒ¨ ì‹œ ìˆ˜ë™ ì—…ë¡œë“œ ì˜µì…˜
        st.header("ğŸ“ ìˆ˜ë™ BOM ë°ì´í„° ì—…ë¡œë“œ")
        st.info("SharePoint ìë™ ì—°ë™ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. BOM ë°ì´í„°ë¥¼ ìˆ˜ë™ìœ¼ë¡œ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
        
        bom_file = st.file_uploader("ğŸ“‹ BOM ë°ì´í„° íŒŒì¼", type=['csv', 'xlsx', 'xls'])
        purchase_file = st.file_uploader("ğŸ’° êµ¬ë§¤ ë°ì´í„° íŒŒì¼", type=['csv', 'xlsx', 'xls'])
        
        if bom_file and purchase_file:
            # ìˆ˜ë™ ì²˜ë¦¬ ë¡œì§
            with st.spinner("ğŸ”„ ë°ì´í„° ì²˜ë¦¬ ë° ê³„ì‚° ì¤‘..."):
                bom_df = safe_load_data(bom_file.getvalue(), bom_file.name, skiprows=1)
                purchase_df = safe_load_data(purchase_file.getvalue(), purchase_file.name)
                
                if bom_df is not None and purchase_df is not None:
                    bom_valid, _ = validate_bom_data(bom_df)
                    
                    if bom_valid:
                        purchase_prices = extract_purchase_prices(purchase_df)
                        
                        if purchase_prices:
                            result_df, details_df = calculate_all_bom_costs(bom_df, purchase_prices)
                            
                            if not result_df.empty:
                                finished_goods = result_df[
                                    result_df['ìƒì‚°í’ˆëª©ëª…'].str.contains('[ì™„ì œí’ˆ]', regex=False, na=False)
                                ].copy()
                                
                                st.balloons()
                                st.success("ğŸ‰ BOM ì›ê°€ ê³„ì‚° ì™„ë£Œ!")
                                
                                # ê°„ë‹¨í•œ ê²°ê³¼ í‘œì‹œ
                                total = len(finished_goods)
                                calculated = len(finished_goods[finished_goods['ê³„ì‚°ìƒíƒœ'] == 'ê³„ì‚°ì™„ë£Œ'])
                                success_rate = (calculated / total * 100) if total > 0 else 0
                                
                                st.metric("ê³„ì‚° ê²°ê³¼", f"ì „ì²´ {total}ê°œ ì¤‘ {calculated}ê°œ ì„±ê³µ ({success_rate:.1f}%)")
                                
                                # ë‹¤ìš´ë¡œë“œ
                                excel_data = export_to_excel(finished_goods, result_df, details_df)
                                if excel_data:
                                    st.download_button(
                                        label="ğŸ“Š ê³„ì‚° ê²°ê³¼ ë‹¤ìš´ë¡œë“œ",
                                        data=excel_data,
                                        file_name=f'BOMì›ê°€ê³„ì‚°_{datetime.now().strftime("%Y%m%d_%H%M")}.xlsx',
                                        mime='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'
                                    )

if __name__ == "__main__":
    main()
