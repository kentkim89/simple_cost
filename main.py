"""
BOM ì›ê°€ ê³„ì‚°ê¸° - ì¥ê¸°ì  ì•ˆì •ì„± ê°•í™” ë²„ì „
ë°ì´í„° ê²€ì¦, ë¡œê¹…, ì˜¤ë¥˜ ì²˜ë¦¬, ì„±ëŠ¥ ìµœì í™” ì ìš©
"""

import streamlit as st
import pandas as pd
import numpy as np
import io
from typing import Dict, List, Tuple, Optional, Any
from pathlib import Path
import time
from datetime import datetime
import traceback
import warnings

# ì„±ëŠ¥ ìµœì í™” (ì„ íƒì  import)
try:
    import bottleneck as bn
    pandas_optimized = True
except ImportError:
    pandas_optimized = False
    st.warning("bottleneck íŒ¨í‚¤ì§€ê°€ ì—†ì–´ pandas ìµœì í™”ê°€ ë¹„í™œì„±í™”ë©ë‹ˆë‹¤.")

# ì§„í–‰ë¥  í‘œì‹œ
try:
    from stqdm import stqdm
    progress_available = True
except ImportError:
    from tqdm import tqdm
    progress_available = False

# ë¡œê¹…
try:
    from loguru import logger
    import sys
    
    # ë¡œê·¸ ì„¤ì •
    logger.remove()  # ê¸°ë³¸ í•¸ë“¤ëŸ¬ ì œê±°
    logger.add(
        sys.stdout, 
        format="<green>{time:YYYY-MM-DD HH:mm:ss}</green> | <level>{level: <8}</level> | <cyan>{name}</cyan>:<cyan>{function}</cyan>:<cyan>{line}</cyan> - <level>{message}</level>",
        level="INFO"
    )
    logging_available = True
except ImportError:
    logging_available = False

# ë°ì´í„° ê²€ì¦
try:
    import pandera as pa
    from pandera import Column, DataFrameSchema, Check
    validation_available = True
except ImportError:
    validation_available = False

# ë¬¸ìì—´ ë§¤ì¹­
try:
    from fuzzywuzzy import fuzz, process
    fuzzy_matching_available = True
except ImportError:
    fuzzy_matching_available = False

# ì‹œê°í™”
try:
    import plotly.express as px
    import plotly.graph_objects as go
    from plotly.subplots import make_subplots
    plotly_available = True
except ImportError:
    plotly_available = False

# ê²½ê³  í•„í„°ë§
warnings.filterwarnings('ignore', category=pd.errors.PerformanceWarning)
warnings.filterwarnings('ignore', category=FutureWarning)

class BOMCalculatorConfig:
    """ì„¤ì • í´ë˜ìŠ¤"""
    MAX_ITERATIONS = 100
    MAX_FILE_SIZE_MB = 100
    CACHE_TIMEOUT = 3600  # 1ì‹œê°„
    SUPPORTED_EXTENSIONS = ['.csv', '.xlsx', '.xls']
    REQUIRED_BOM_COLUMNS = ['ìƒì‚°í’ˆëª©ì½”ë“œ', 'ìƒì‚°í’ˆëª©ëª…', 'ì†Œëª¨í’ˆëª©ì½”ë“œ', 'ì†Œëª¨í’ˆëª©ëª…', 'ì†Œìš”ëŸ‰']
    TEST_ITEM_CODE = '99701'

class DataValidator:
    """ë°ì´í„° ê²€ì¦ í´ë˜ìŠ¤"""
    
    @staticmethod
    def validate_file_size(file_obj, max_size_mb: int = 100) -> bool:
        """íŒŒì¼ í¬ê¸° ê²€ì¦"""
        try:
            file_size = len(file_obj.getvalue()) / (1024 * 1024)  # MB
            if file_size > max_size_mb:
                st.error(f"âŒ íŒŒì¼ í¬ê¸°ê°€ {max_size_mb}MBë¥¼ ì´ˆê³¼í•©ë‹ˆë‹¤. ({file_size:.1f}MB)")
                return False
            return True
        except Exception as e:
            if logging_available:
                logger.error(f"íŒŒì¼ í¬ê¸° ê²€ì¦ ì˜¤ë¥˜: {e}")
            st.error(f"íŒŒì¼ í¬ê¸° ê²€ì¦ ì¤‘ ì˜¤ë¥˜: {e}")
            return False

    @staticmethod
    def validate_bom_schema(df: pd.DataFrame) -> Tuple[bool, List[str]]:
        """BOM ë°ì´í„° ìŠ¤í‚¤ë§ˆ ê²€ì¦"""
        if not validation_available:
            # ê¸°ë³¸ ê²€ì¦
            required_cols = BOMCalculatorConfig.REQUIRED_BOM_COLUMNS
            missing_cols = [col for col in required_cols if col not in df.columns]
            return len(missing_cols) == 0, missing_cols
        
        try:
            # pandera ìŠ¤í‚¤ë§ˆ ì •ì˜
            bom_schema = DataFrameSchema({
                "ìƒì‚°í’ˆëª©ì½”ë“œ": Column(pa.String, nullable=False, checks=Check.str_length(min_value=1)),
                "ìƒì‚°í’ˆëª©ëª…": Column(pa.String, nullable=False, checks=Check.str_length(min_value=1)),
                "ì†Œëª¨í’ˆëª©ì½”ë“œ": Column(pa.String, nullable=False, checks=Check.str_length(min_value=1)),
                "ì†Œëª¨í’ˆëª©ëª…": Column(pa.String, nullable=False, checks=Check.str_length(min_value=1)),
                "ì†Œìš”ëŸ‰": Column(pa.Float, nullable=False, checks=Check.greater_than_or_equal_to(0))
            })
            
            # ê²€ì¦ ì‹¤í–‰
            bom_schema.validate(df, lazy=True)
            return True, []
            
        except pa.errors.SchemaError as e:
            error_messages = []
            for failure in e.failure_cases.itertuples():
                error_messages.append(f"ì»¬ëŸ¼ '{failure.column}': {failure.check}")
            
            if logging_available:
                logger.error(f"BOM ìŠ¤í‚¤ë§ˆ ê²€ì¦ ì‹¤íŒ¨: {error_messages}")
            
            return False, error_messages
        except Exception as e:
            if logging_available:
                logger.error(f"ìŠ¤í‚¤ë§ˆ ê²€ì¦ ì¤‘ ì˜ˆì™¸: {e}")
            return False, [str(e)]

    @staticmethod
    def validate_purchase_data(df: pd.DataFrame) -> Tuple[bool, str]:
        """êµ¬ë§¤ ë°ì´í„° ê²€ì¦"""
        try:
            if df.empty:
                return False, "êµ¬ë§¤ ë°ì´í„°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤"
            
            if len(df.columns) < 3:
                return False, "êµ¬ë§¤ ë°ì´í„°ì˜ ì»¬ëŸ¼ì´ ë¶€ì¡±í•©ë‹ˆë‹¤"
                
            # í•„ìˆ˜ ë°ì´í„° ì¡´ì¬ ì—¬ë¶€
            non_empty_rows = df.dropna(how='all')
            if len(non_empty_rows) < 1:
                return False, "ìœ íš¨í•œ êµ¬ë§¤ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤"
                
            return True, "ê²€ì¦ ì„±ê³µ"
            
        except Exception as e:
            return False, f"êµ¬ë§¤ ë°ì´í„° ê²€ì¦ ì˜¤ë¥˜: {str(e)}"

class SecureFileLoader:
    """ì•ˆì „í•œ íŒŒì¼ ë¡œë”"""
    
    @staticmethod
    @st.cache_data(ttl=BOMCalculatorConfig.CACHE_TIMEOUT, show_spinner=False)
    def load_data(file_content: bytes, file_name: str, skiprows: int = 0) -> Optional[pd.DataFrame]:
        """ìºì‹œëœ ì•ˆì „í•œ ë°ì´í„° ë¡œë”©"""
        try:
            # íŒŒì¼ í™•ì¥ì ê²€ì¦
            file_path = Path(file_name)
            if file_path.suffix.lower() not in BOMCalculatorConfig.SUPPORTED_EXTENSIONS:
                st.error(f"âŒ ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹: {file_path.suffix}")
                return None
            
            # ë©”ëª¨ë¦¬ì—ì„œ íŒŒì¼ ì½ê¸°
            file_obj = io.BytesIO(file_content)
            
            if logging_available:
                logger.info(f"íŒŒì¼ ë¡œë”© ì‹œì‘: {file_name}")
            
            # íŒŒì¼ íƒ€ì…ë³„ ë¡œë”©
            if file_path.suffix.lower() == '.csv':
                # CSV ì¸ì½”ë”© ìë™ ê°ì§€ ì‹œë„
                encodings = ['utf-8-sig', 'utf-8', 'cp949', 'euc-kr']
                df = None
                
                for encoding in encodings:
                    try:
                        file_obj.seek(0)
                        df = pd.read_csv(
                            file_obj, 
                            skiprows=skiprows, 
                            encoding=encoding, 
                            dtype=str,
                            na_values=['', 'NULL', 'null', 'NaN', 'nan']
                        )
                        if logging_available:
                            logger.info(f"CSV ì¸ì½”ë”© ì„±ê³µ: {encoding}")
                        break
                    except (UnicodeDecodeError, pd.errors.EmptyDataError):
                        continue
                
                if df is None:
                    st.error("âŒ CSV íŒŒì¼ ì¸ì½”ë”©ì„ ê°ì§€í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                    return None
                    
            elif file_path.suffix.lower() in ['.xlsx', '.xls']:
                try:
                    df = pd.read_excel(
                        file_obj, 
                        skiprows=skiprows, 
                        dtype=str,
                        na_values=['', 'NULL', 'null', 'NaN', 'nan']
                    )
                except Exception as e:
                    st.error(f"âŒ Excel íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {e}")
                    return None
            
            # ë°ì´í„° ì •ì œ
            if df is not None:
                # ì¢Œìš° ê³µë°± ì œê±°
                for col in df.select_dtypes(include=['object']).columns:
                    df[col] = df[col].astype(str).str.strip()
                
                # ì™„ì „íˆ ë¹ˆ í–‰/ì—´ ì œê±°
                df = df.dropna(how='all').dropna(axis=1, how='all')
                
                if logging_available:
                    logger.info(f"íŒŒì¼ ë¡œë”© ì™„ë£Œ: {len(df)}í–‰ Ã— {len(df.columns)}ì—´")
                
                return df
            
            return None
            
        except Exception as e:
            if logging_available:
                logger.error(f"íŒŒì¼ ë¡œë”© ì‹¤íŒ¨: {file_name}, ì˜¤ë¥˜: {str(e)}")
            st.error(f"âŒ íŒŒì¼ ë¡œë”© ì‹¤íŒ¨: {str(e)}")
            return None

class PurchasePriceExtractor:
    """êµ¬ë§¤ ë‹¨ê°€ ì¶”ì¶œê¸°"""
    
    @staticmethod
    def extract_prices(df: pd.DataFrame) -> Dict[str, float]:
        """êµ¬ë§¤ ë°ì´í„°ì—ì„œ ì•ˆì „í•˜ê²Œ ìµœì‹  ë‹¨ê°€ ì¶”ì¶œ"""
        try:
            if df.empty:
                if logging_available:
                    logger.warning("ë¹ˆ êµ¬ë§¤ ë°ì´í„°")
                return {}
            
            # ì»¬ëŸ¼ëª… ìë™ ê°ì§€
            column_mapping = PurchasePriceExtractor._detect_columns(df)
            
            if not all(column_mapping.values()):
                if logging_available:
                    logger.warning(f"í•„ìˆ˜ ì»¬ëŸ¼ ê°ì§€ ì‹¤íŒ¨: {column_mapping}")
                st.warning("âš ï¸ êµ¬ë§¤ ë°ì´í„°ì—ì„œ í•„ìˆ˜ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                return {}
            
            # ë°ì´í„° ì •ì œ ë° ë³€í™˜
            clean_df = PurchasePriceExtractor._clean_purchase_data(df, column_mapping)
            
            if clean_df.empty:
                if logging_available:
                    logger.warning("ì •ì œ í›„ êµ¬ë§¤ ë°ì´í„°ê°€ ë¹„ì–´ìˆìŒ")
                return {}
            
            # ìµœì‹  ë‹¨ê°€ ì¶”ì¶œ
            price_dict = PurchasePriceExtractor._extract_latest_prices(clean_df)
            
            if logging_available:
                logger.info(f"êµ¬ë§¤ ë‹¨ê°€ ì¶”ì¶œ ì™„ë£Œ: {len(price_dict)}ê°œ í’ˆëª©")
            
            return price_dict
            
        except Exception as e:
            if logging_available:
                logger.error(f"êµ¬ë§¤ ë‹¨ê°€ ì¶”ì¶œ ì˜¤ë¥˜: {str(e)}")
            st.error(f"âŒ êµ¬ë§¤ ë‹¨ê°€ ì¶”ì¶œ ì˜¤ë¥˜: {str(e)}")
            return {}
    
    @staticmethod
    def _detect_columns(df: pd.DataFrame) -> Dict[str, Optional[str]]:
        """ì»¬ëŸ¼ëª… ìë™ ê°ì§€"""
        column_mapping = {'date': None, 'item_code': None, 'price': None}
        
        # ì²« ë²ˆì§¸ í–‰ì´ í—¤ë”ì¸ì§€ í™•ì¸ (íšŒì‚¬ëª… ë“±ì´ ìˆìœ¼ë©´ ê±´ë„ˆë›°ê¸°)
        first_row_text = ' '.join([str(val) for val in df.iloc[0].values if pd.notna(val)])
        if any(keyword in first_row_text for keyword in ['íšŒì‚¬ëª…', 'ê¸°ê°„', 'ë‚ ì§œ', 'ì¡°íšŒ']):
            # ë‹¤ìŒ í–‰ì„ í—¤ë”ë¡œ ì‚¬ìš©
            if len(df) > 1:
                new_headers = df.iloc[1].fillna('').astype(str).tolist()
                df_temp = df.iloc[2:].copy()
                df_temp.columns = new_headers[:len(df_temp.columns)]
            else:
                df_temp = df
        else:
            df_temp = df
        
        # ì»¬ëŸ¼ëª…ìœ¼ë¡œ ë§¤í•‘
        for col in df_temp.columns:
            col_str = str(col).lower()
            
            if not column_mapping['date'] and any(keyword in col_str for keyword in ['ì¼ì', 'date', 'ë‚ ì§œ']):
                column_mapping['date'] = col
            elif not column_mapping['item_code'] and 'í’ˆëª©ì½”ë“œ' in col_str:
                column_mapping['item_code'] = col
            elif not column_mapping['price'] and 'ë‹¨ê°€' in col_str and 'ê³µê¸‰' not in col_str:
                column_mapping['price'] = col
        
        # ê¸°ë³¸ê°’ í• ë‹¹ (ì»¬ëŸ¼ì„ ì°¾ì§€ ëª»í•œ ê²½ìš°)
        if not column_mapping['date'] and len(df_temp.columns) > 0:
            column_mapping['date'] = df_temp.columns[0]
        if not column_mapping['item_code'] and len(df_temp.columns) > 1:
            column_mapping['item_code'] = df_temp.columns[1]
        if not column_mapping['price'] and len(df_temp.columns) > 5:
            column_mapping['price'] = df_temp.columns[5]
        
        return column_mapping
    
    @staticmethod
    def _clean_purchase_data(df: pd.DataFrame, column_mapping: Dict[str, str]) -> pd.DataFrame:
        """êµ¬ë§¤ ë°ì´í„° ì •ì œ"""
        try:
            # í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì¶”ì¶œ
            clean_df = df[[column_mapping['date'], column_mapping['item_code'], column_mapping['price']]].copy()
            clean_df.columns = ['date', 'item_code', 'price']
            
            # ë¹ˆ ê°’ ì œê±°
            clean_df = clean_df.dropna()
            
            # ë‚ ì§œ ë³€í™˜
            clean_df['date_str'] = clean_df['date'].astype(str)
            clean_df['date_clean'] = clean_df['date_str'].str.split('-').str[0]
            clean_df['date_parsed'] = pd.to_datetime(clean_df['date_clean'], errors='coerce')
            
            # ë‚ ì§œ ë³€í™˜ì— ì‹¤íŒ¨í•œ í–‰ ì œê±°
            clean_df = clean_df.dropna(subset=['date_parsed'])
            
            # í’ˆëª©ì½”ë“œì™€ ë‹¨ê°€ ì •ì œ
            clean_df['item_code'] = clean_df['item_code'].astype(str).str.strip()
            clean_df['price'] = pd.to_numeric(clean_df['price'], errors='coerce')
            
            # ìœ íš¨í•˜ì§€ ì•Šì€ ë°ì´í„° ì œê±°
            clean_df = clean_df[
                (clean_df['item_code'] != '') & 
                (clean_df['item_code'] != 'nan') & 
                (clean_df['price'] > 0) & 
                (clean_df['price'].notna())
            ]
            
            return clean_df
            
        except Exception as e:
            if logging_available:
                logger.error(f"êµ¬ë§¤ ë°ì´í„° ì •ì œ ì˜¤ë¥˜: {str(e)}")
            return pd.DataFrame()
    
    @staticmethod
    def _extract_latest_prices(df: pd.DataFrame) -> Dict[str, float]:
        """ìµœì‹  ë‹¨ê°€ ì¶”ì¶œ"""
        try:
            # ë‚ ì§œìˆœ ì •ë ¬ (ìµœì‹  ìˆœ)
            df_sorted = df.sort_values('date_parsed', ascending=False)
            
            # í’ˆëª©ë³„ ìµœì‹  ë‹¨ê°€ë§Œ ì¶”ì¶œ
            latest_prices = df_sorted.drop_duplicates(subset='item_code', keep='first')
            
            # ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
            price_dict = {}
            for _, row in latest_prices.iterrows():
                item_code = row['item_code']
                price = row['price']
                if pd.notna(price) and price > 0:
                    price_dict[item_code] = float(price)
            
            return price_dict
            
        except Exception as e:
            if logging_available:
                logger.error(f"ìµœì‹  ë‹¨ê°€ ì¶”ì¶œ ì˜¤ë¥˜: {str(e)}")
            return {}

class BOMCostCalculator:
    """BOM ì›ê°€ ê³„ì‚°ê¸° - ê°œì„ ëœ ë²„ì „"""
    
    def __init__(self):
        self.calculation_cache = {}
        self.calculation_log = []
    
    def calculate_all_costs(self, bom_df: pd.DataFrame, purchase_prices: Dict[str, float]) -> Tuple[pd.DataFrame, pd.DataFrame]:
        """ëª¨ë“  ì œí’ˆì˜ BOM ì›ê°€ ê³„ì‚°"""
        try:
            start_time = time.time()
            
            if logging_available:
                logger.info("BOM ì›ê°€ ê³„ì‚° ì‹œì‘")
            
            # ë°ì´í„° ê²€ì¦
            is_valid, validation_errors = DataValidator.validate_bom_schema(bom_df)
            if not is_valid:
                st.error("âŒ BOM ë°ì´í„° ê²€ì¦ ì‹¤íŒ¨:")
                for error in validation_errors:
                    st.error(f"  â€¢ {error}")
                return pd.DataFrame(), pd.DataFrame()
            
            # ë°ì´í„° ì •ì œ
            clean_bom = self._clean_bom_data(bom_df)
            
            if clean_bom.empty:
                st.error("âŒ BOM ë°ì´í„° ì •ì œ í›„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
                return pd.DataFrame(), pd.DataFrame()
            
            # ëª¨ë“  ìƒì‚°í’ˆëª© ëª©ë¡
            all_products = clean_bom[['ìƒì‚°í’ˆëª©ì½”ë“œ', 'ìƒì‚°í’ˆëª©ëª…']].drop_duplicates().reset_index(drop=True)
            
            if logging_available:
                logger.info(f"ê³„ì‚° ëŒ€ìƒ: {len(all_products)}ê°œ ìƒì‚°í’ˆëª©, {len(purchase_prices)}ê°œ êµ¬ë§¤ë‹¨ê°€")
            
            # ì „ì²´ ë‹¨ê°€ ë”•ì…”ë„ˆë¦¬ ì´ˆê¸°í™”
            all_costs = purchase_prices.copy()
            self.calculation_cache = {}
            self.calculation_log = []
            
            # ì§„í–‰ë¥  í‘œì‹œì™€ í•¨ê»˜ ê³„ì‚°
            results = []
            
            if progress_available:
                progress_bar = stqdm(all_products.iterrows(), total=len(all_products), desc="BOM ì›ê°€ ê³„ì‚°")
            else:
                progress_bar = all_products.iterrows()
                st_progress = st.progress(0)
            
            for idx, (_, product) in enumerate(progress_bar):
                product_code = product['ìƒì‚°í’ˆëª©ì½”ë“œ']
                product_name = product['ìƒì‚°í’ˆëª©ëª…']
                
                # ì§ì ‘ ê³„ì‚°
                calculated_cost = self._calculate_product_cost(product_code, clean_bom, all_costs)
                
                results.append({
                    'ìƒì‚°í’ˆëª©ì½”ë“œ': product_code,
                    'ìƒì‚°í’ˆëª©ëª…': product_name,
                    'ê³„ì‚°ëœë‹¨ìœ„ì›ê°€': calculated_cost,
                    'ê³„ì‚°ìƒíƒœ': 'ê³„ì‚°ì™„ë£Œ' if calculated_cost > 0 else 'ê³„ì‚°ë¶ˆê°€'
                })
                
                # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸ (stqdmì´ ì—†ëŠ” ê²½ìš°)
                if not progress_available:
                    st_progress.progress((idx + 1) / len(all_products))
            
            if not progress_available:
                st_progress.empty()
            
            # ê²°ê³¼ DataFrame ìƒì„±
            result_df = pd.DataFrame(results)
            
            # ìƒì„¸ ë‚´ì—­ ìƒì„±
            details_df = self._generate_details(clean_bom, all_costs)
            
            # ê³„ì‚° ì‹œê°„ ê¸°ë¡
            elapsed_time = time.time() - start_time
            
            if logging_available:
                logger.info(f"BOM ì›ê°€ ê³„ì‚° ì™„ë£Œ: {elapsed_time:.2f}ì´ˆ")
            
            st.success(f"âœ… BOM ì›ê°€ ê³„ì‚° ì™„ë£Œ! (ì†Œìš”ì‹œê°„: {elapsed_time:.2f}ì´ˆ)")
            
            return result_df, details_df
            
        except Exception as e:
            if logging_available:
                logger.error(f"BOM ì›ê°€ ê³„ì‚° ì¤‘ ì˜¤ë¥˜: {str(e)}")
                logger.error(f"ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤: {traceback.format_exc()}")
            st.error(f"âŒ BOM ì›ê°€ ê³„ì‚° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return pd.DataFrame(), pd.DataFrame()
    
    def _clean_bom_data(self, bom_df: pd.DataFrame) -> pd.DataFrame:
        """BOM ë°ì´í„° ì •ì œ"""
        try:
            clean_df = bom_df.copy()
            
            # í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸
            required_cols = BOMCalculatorConfig.REQUIRED_BOM_COLUMNS
            missing_cols = [col for col in required_cols if col not in clean_df.columns]
            
            if missing_cols:
                st.error(f"âŒ BOM ë°ì´í„°ì— í•„ìˆ˜ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤: {missing_cols}")
                return pd.DataFrame()
            
            # ë°ì´í„° íƒ€ì… ì •ì œ
            clean_df['ìƒì‚°í’ˆëª©ì½”ë“œ'] = clean_df['ìƒì‚°í’ˆëª©ì½”ë“œ'].astype(str).str.strip()
            clean_df['ì†Œëª¨í’ˆëª©ì½”ë“œ'] = clean_df['ì†Œëª¨í’ˆëª©ì½”ë“œ'].astype(str).str.strip()
            clean_df['ì†Œìš”ëŸ‰'] = pd.to_numeric(clean_df['ì†Œìš”ëŸ‰'], errors='coerce').fillna(0)
            
            # test í’ˆëª© ì œê±°
            before_count = len(clean_df)
            clean_df = clean_df[clean_df['ì†Œëª¨í’ˆëª©ì½”ë“œ'] != BOMCalculatorConfig.TEST_ITEM_CODE]
            after_count = len(clean_df)
            
            if before_count != after_count:
                st.info(f"ğŸ§¹ test í’ˆëª©({BOMCalculatorConfig.TEST_ITEM_CODE}) ì œê±°: {before_count:,} â†’ {after_count:,}í–‰")
            
            # ìœ íš¨í•˜ì§€ ì•Šì€ ë°ì´í„° ì œê±°
            clean_df = clean_df[
                (clean_df['ìƒì‚°í’ˆëª©ì½”ë“œ'] != '') &
                (clean_df['ì†Œëª¨í’ˆëª©ì½”ë“œ'] != '') &
                (clean_df['ìƒì‚°í’ˆëª©ì½”ë“œ'] != 'nan') &
                (clean_df['ì†Œëª¨í’ˆëª©ì½”ë“œ'] != 'nan') &
                (clean_df['ì†Œìš”ëŸ‰'] >= 0)
            ]
            
            return clean_df
            
        except Exception as e:
            if logging_available:
                logger.error(f"BOM ë°ì´í„° ì •ì œ ì˜¤ë¥˜: {str(e)}")
            return pd.DataFrame()
    
    def _calculate_product_cost(self, product_code: str, bom_df: pd.DataFrame, all_costs: Dict[str, float]) -> float:
        """ë‹¨ì¼ ì œí’ˆì˜ ì›ê°€ ê³„ì‚° (ì¬ê·€ì )"""
        try:
            # ìºì‹œ í™•ì¸
            if product_code in self.calculation_cache:
                return self.calculation_cache[product_code]
            
            # í•´ë‹¹ ì œí’ˆì˜ BOM êµ¬ì„±ìš”ì†Œ
            components = bom_df[bom_df['ìƒì‚°í’ˆëª©ì½”ë“œ'] == product_code]
            
            if components.empty:
                self.calculation_cache[product_code] = 0.0
                return 0.0
            
            total_cost = 0.0
            component_details = []
            
            for _, comp in components.iterrows():
                comp_code = comp['ì†Œëª¨í’ˆëª©ì½”ë“œ']
                comp_name = comp['ì†Œëª¨í’ˆëª©ëª…']
                quantity = float(comp['ì†Œìš”ëŸ‰'])
                
                # ë¶€í’ˆ ë‹¨ê°€ ì°¾ê¸°
                if comp_code in all_costs:
                    # ì´ë¯¸ ì•Œë ¤ì§„ ë‹¨ê°€
                    unit_price = all_costs[comp_code]
                else:
                    # ë‹¤ë¥¸ ìƒì‚°í’ˆëª©ì¸ì§€ í™•ì¸í•˜ì—¬ ì¬ê·€ ê³„ì‚°
                    if comp_code in bom_df['ìƒì‚°í’ˆëª©ì½”ë“œ'].values:
                        unit_price = self._calculate_product_cost(comp_code, bom_df, all_costs)
                        all_costs[comp_code] = unit_price  # ìºì‹œ ì—…ë°ì´íŠ¸
                    else:
                        unit_price = 0.0
                
                component_cost = quantity * unit_price
                total_cost += component_cost
                
                component_details.append({
                    'ë¶€í’ˆì½”ë“œ': comp_code,
                    'ë¶€í’ˆëª…': comp_name,
                    'ì†Œìš”ëŸ‰': quantity,
                    'ë‹¨ê°€': unit_price,
                    'ë¶€í’ˆì›ê°€': component_cost
                })
            
            # ìºì‹œì— ì €ì¥
            self.calculation_cache[product_code] = total_cost
            
            # ë¡œê·¸ ì €ì¥
            if total_cost > 0:
                self.calculation_log.append({
                    'ì œí’ˆì½”ë“œ': product_code,
                    'ì´ì›ê°€': total_cost,
                    'êµ¬ì„±ìš”ì†Œìˆ˜': len(component_details)
                })
            
            return total_cost
            
        except Exception as e:
            if logging_available:
                logger.error(f"ì œí’ˆ {product_code} ì›ê°€ ê³„ì‚° ì˜¤ë¥˜: {str(e)}")
            return 0.0
    
    def _generate_details(self, bom_df: pd.DataFrame, all_costs: Dict[str, float]) -> pd.DataFrame:
        """ìƒì„¸ ë‚´ì—­ ìƒì„±"""
        try:
            details_df = bom_df.copy()
            details_df['ë¶€í’ˆë‹¨ê°€'] = details_df['ì†Œëª¨í’ˆëª©ì½”ë“œ'].map(all_costs).fillna(0)
            details_df['ë¶€í’ˆë³„ì›ê°€'] = details_df['ì†Œìš”ëŸ‰'] * details_df['ë¶€í’ˆë‹¨ê°€']
            
            return details_df
            
        except Exception as e:
            if logging_available:
                logger.error(f"ìƒì„¸ ë‚´ì—­ ìƒì„± ì˜¤ë¥˜: {str(e)}")
            return pd.DataFrame()

class ExcelExporter:
    """ì•ˆì „í•œ ì—‘ì…€ ë‚´ë³´ë‚´ê¸°"""
    
    @staticmethod
    def export_results(finished_goods: pd.DataFrame, all_results: pd.DataFrame, details: pd.DataFrame) -> bytes:
        """ê²°ê³¼ë¥¼ ì—‘ì…€ë¡œ ë‚´ë³´ë‚´ê¸°"""
        try:
            output = io.BytesIO()
            
            with pd.ExcelWriter(output, engine='openpyxl') as writer:
                # ì™„ì œí’ˆ ê²°ê³¼
                ExcelExporter._write_sheet_with_formatting(
                    writer, finished_goods, 'ì™„ì œí’ˆì›ê°€ê²°ê³¼', 
                    'ì™„ì œí’ˆ BOM ì›ê°€ ê³„ì‚° ê²°ê³¼'
                )
                
                # ì „ì²´ ê²°ê³¼
                ExcelExporter._write_sheet_with_formatting(
                    writer, all_results, 'ì „ì²´ì œí’ˆì›ê°€',
                    'ì „ì²´ ì œí’ˆ ì›ê°€ ê³„ì‚° ê²°ê³¼'
                )
                
                # ìƒì„¸ ë‚´ì—­
                ExcelExporter._write_sheet_with_formatting(
                    writer, details, 'BOMìƒì„¸ë‚´ì—­',
                    'BOM êµ¬ì„±ìš”ì†Œë³„ ìƒì„¸ ì›ê°€ ë‚´ì—­'
                )
            
            return output.getvalue()
            
        except Exception as e:
            if logging_available:
                logger.error(f"ì—‘ì…€ ë‚´ë³´ë‚´ê¸° ì˜¤ë¥˜: {str(e)}")
            st.error(f"âŒ ì—‘ì…€ íŒŒì¼ ìƒì„± ì˜¤ë¥˜: {str(e)}")
            return b''
    
    @staticmethod
    def _write_sheet_with_formatting(writer, df: pd.DataFrame, sheet_name: str, title: str):
        """ì‹œíŠ¸ë³„ í¬ë§·íŒ… ì ìš©"""
        try:
            # ê¸°ë³¸ ë°ì´í„° ì“°ê¸°
            df.to_excel(writer, sheet_name=sheet_name, index=False, startrow=2)
            
            worksheet = writer.sheets[sheet_name]
            
            # ì œëª© ì¶”ê°€
            worksheet.cell(row=1, column=1, value=title)
            
            # ìŠ¤íƒ€ì¼ ì ìš© ì‹œë„
            try:
                from openpyxl.styles import PatternFill, Font, Alignment
                from openpyxl.utils import get_column_letter
                
                # ì œëª© ìŠ¤íƒ€ì¼
                title_cell = worksheet.cell(row=1, column=1)
                title_cell.font = Font(size=14, bold=True)
                title_cell.alignment = Alignment(horizontal='center')
                
                # í—¤ë” ìŠ¤íƒ€ì¼
                header_fill = PatternFill(start_color="366092", end_color="366092", fill_type="solid")
                header_font = Font(color="FFFFFF", bold=True)
                
                for col in range(1, len(df.columns) + 1):
                    cell = worksheet.cell(row=3, column=col)
                    cell.fill = header_fill
                    cell.font = header_font
                    cell.alignment = Alignment(horizontal='center')
                
                # ì»¬ëŸ¼ ë„ˆë¹„ ì¡°ì •
                for col in range(1, len(df.columns) + 1):
                    column = df.columns[col-1]
                    max_length = max(
                        len(str(column)),
                        df[column].astype(str).str.len().max() if not df.empty else 0
                    )
                    adjusted_width = min(max_length + 3, 50)
                    column_letter = get_column_letter(col)
                    worksheet.column_dimensions[column_letter].width = adjusted_width
                
            except ImportError:
                # openpyxl ìŠ¤íƒ€ì¼ ëª¨ë“ˆì„ importí•  ìˆ˜ ì—†ëŠ” ê²½ìš°
                pass
                
        except Exception as e:
            if logging_available:
                logger.warning(f"ì‹œíŠ¸ í¬ë§·íŒ… ì˜¤ë¥˜: {e}")

class DataVisualizer:
    """ë°ì´í„° ì‹œê°í™” í´ë˜ìŠ¤"""
    
    @staticmethod
    def create_cost_analysis_charts(finished_goods: pd.DataFrame) -> None:
        """ì›ê°€ ë¶„ì„ ì°¨íŠ¸ ìƒì„±"""
        if not plotly_available:
            st.info("ğŸ“Š plotlyê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•„ ì‹œê°í™”ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
            return
        
        try:
            if finished_goods.empty:
                return
            
            # ë°ì´í„° ì¤€ë¹„
            chart_data = finished_goods[finished_goods['ê³„ì‚°ëœë‹¨ìœ„ì›ê°€'] > 0].copy()
            
            if chart_data.empty:
                st.warning("âš ï¸ ì°¨íŠ¸ë¥¼ ê·¸ë¦´ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return
            
            # 1. ì›ê°€ ë¶„í¬ íˆìŠ¤í† ê·¸ë¨
            st.subheader("ğŸ“Š ì™„ì œí’ˆ ì›ê°€ ë¶„í¬")
            
            fig_hist = px.histogram(
                chart_data, 
                x='ê³„ì‚°ëœë‹¨ìœ„ì›ê°€',
                nbins=20,
                title='ì™„ì œí’ˆ ì›ê°€ ë¶„í¬',
                labels={'ê³„ì‚°ëœë‹¨ìœ„ì›ê°€': 'ì›ê°€ (ì›)', 'count': 'ì œí’ˆ ìˆ˜'}
            )
            fig_hist.update_layout(showlegend=False)
            st.plotly_chart(fig_hist, use_container_width=True)
            
            # 2. ìƒìœ„ ì›ê°€ ì œí’ˆ TOP 20
            if len(chart_data) >= 10:
                st.subheader("ğŸ’° ì›ê°€ ìƒìœ„ 20ê°œ ì™„ì œí’ˆ")
                
                top_products = chart_data.nlargest(20, 'ê³„ì‚°ëœë‹¨ìœ„ì›ê°€')
                
                fig_bar = px.bar(
                    top_products,
                    x='ê³„ì‚°ëœë‹¨ìœ„ì›ê°€',
                    y='ìƒì‚°í’ˆëª©ì½”ë“œ',
                    orientation='h',
                    title='ì›ê°€ ìƒìœ„ 20ê°œ ì™„ì œí’ˆ',
                    labels={'ê³„ì‚°ëœë‹¨ìœ„ì›ê°€': 'ì›ê°€ (ì›)', 'ìƒì‚°í’ˆëª©ì½”ë“œ': 'ì œí’ˆì½”ë“œ'}
                )
                fig_bar.update_layout(height=600, yaxis={'categoryorder': 'total ascending'})
                st.plotly_chart(fig_bar, use_container_width=True)
            
            # 3. ì›ê°€ êµ¬ê°„ë³„ ë¶„í¬
            st.subheader("ğŸ“ˆ ì›ê°€ êµ¬ê°„ë³„ ì œí’ˆ ë¶„í¬")
            
            # ì›ê°€ êµ¬ê°„ ì •ì˜
            bins = [0, 1000, 5000, 10000, 50000, 100000, float('inf')]
            labels = ['~1ì²œì›', '1ì²œ~5ì²œì›', '5ì²œ~1ë§Œì›', '1ë§Œ~5ë§Œì›', '5ë§Œ~10ë§Œì›', '10ë§Œì›+']
            
            chart_data['ì›ê°€êµ¬ê°„'] = pd.cut(chart_data['ê³„ì‚°ëœë‹¨ìœ„ì›ê°€'], bins=bins, labels=labels)
            cost_distribution = chart_data['ì›ê°€êµ¬ê°„'].value_counts().sort_index()
            
            fig_pie = px.pie(
                values=cost_distribution.values,
                names=cost_distribution.index,
                title='ì›ê°€ êµ¬ê°„ë³„ ì œí’ˆ ë¶„í¬'
            )
            st.plotly_chart(fig_pie, use_container_width=True)
            
        except Exception as e:
            if logging_available:
                logger.error(f"ì°¨íŠ¸ ìƒì„± ì˜¤ë¥˜: {str(e)}")
            st.warning(f"âš ï¸ ì°¨íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")

def main():
    """ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜"""
    
    # í˜ì´ì§€ ì„¤ì •
    st.set_page_config(
        page_title="BOM ì›ê°€ ê³„ì‚°ê¸°",
        page_icon="ğŸ­",
        layout="wide",
        initial_sidebar_state="expanded"
    )
    
    # ì œëª© ë° ì„¤ëª…
    st.title("ğŸ­ BOM ì›ê°€ ê³„ì‚°ê¸° (ì¥ê¸°ì  ì•ˆì •ì„± ê°•í™” ë²„ì „)")
    st.markdown("""
    **âœ¨ ì£¼ìš” ê¸°ëŠ¥**
    - ğŸ“‹ ë°ì´í„° ê²€ì¦ ë° ìŠ¤í‚¤ë§ˆ í™•ì¸
    - ğŸ”„ ì¬ê·€ì  ë‹¤ë‹¨ê³„ BOM ì›ê°€ ê³„ì‚°  
    - ğŸ“Š ì‹¤ì‹œê°„ ì§„í–‰ë¥  í‘œì‹œ
    - ğŸ¯ ì‹œê°ì  ì›ê°€ ë¶„ì„
    - ğŸ“¥ í¬ë§·íŒ…ëœ ì—‘ì…€ ì¶œë ¥
    - ğŸ›¡ï¸ ì•ˆì „í•œ ì˜¤ë¥˜ ì²˜ë¦¬
    """)
    
    # ì‚¬ì´ë“œë°” ì„¤ì •
    with st.sidebar:
        st.header("âš™ï¸ ê³„ì‚° ì„¤ì •")
        
        # ê³ ê¸‰ ì˜µì…˜
        show_debug = st.checkbox("ğŸ” ë””ë²„ê¹… ì •ë³´ í‘œì‹œ", value=False)
        show_charts = st.checkbox("ğŸ“Š ì‹œê°í™” ì°¨íŠ¸ í‘œì‹œ", value=True)
        
        st.header("ğŸ“Š ì‹œìŠ¤í…œ ì •ë³´")
        st.info(f"""
        **í™œì„±í™”ëœ ê¸°ëŠ¥:**
        - ë¡œê¹…: {'âœ…' if logging_available else 'âŒ'}
        - ë°ì´í„° ê²€ì¦: {'âœ…' if validation_available else 'âŒ'}
        - ì§„í–‰ë¥  í‘œì‹œ: {'âœ…' if progress_available else 'âŒ'}
        - ì‹œê°í™”: {'âœ…' if plotly_available else 'âŒ'}
        - pandas ìµœì í™”: {'âœ…' if pandas_optimized else 'âŒ'}
        - ë¬¸ìì—´ ë§¤ì¹­: {'âœ…' if fuzzy_matching_available else 'âŒ'}
        """)
    
    # ë©”ì¸ ì¸í„°í˜ì´ìŠ¤
    st.header("1. ğŸ“ íŒŒì¼ ì—…ë¡œë“œ")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("ğŸ“‹ BOM ë°ì´í„°")
        bom_file = st.file_uploader(
            "BOM íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”",
            type=['csv', 'xlsx', 'xls'],
            key="bom_file",
            help="ìƒì‚°í’ˆëª©ì½”ë“œ, ìƒì‚°í’ˆëª©ëª…, ì†Œëª¨í’ˆëª©ì½”ë“œ, ì†Œëª¨í’ˆëª©ëª…, ì†Œìš”ëŸ‰ ì»¬ëŸ¼ì´ í•„ìš”í•©ë‹ˆë‹¤"
        )
        
    with col2:
        st.subheader("ğŸ’° êµ¬ë§¤ ë°ì´í„°") 
        purchase_file = st.file_uploader(
            "êµ¬ë§¤ ë°ì´í„° íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”",
            type=['csv', 'xlsx', 'xls'],
            key="purchase_file",
            help="ì¼ì, í’ˆëª©ì½”ë“œ, ë‹¨ê°€ ì»¬ëŸ¼ì´ í•„ìš”í•©ë‹ˆë‹¤"
        )
    
    # íŒŒì¼ ê²€ì¦ ë° ë¡œë”©
    if bom_file and purchase_file:
        
        # íŒŒì¼ í¬ê¸° ê²€ì¦
        if not DataValidator.validate_file_size(bom_file) or not DataValidator.validate_file_size(purchase_file):
            st.stop()
        
        # ë°ì´í„° ë¡œë”©
        with st.spinner("ğŸ“– íŒŒì¼ì„ ì½ëŠ” ì¤‘..."):
            bom_df = SecureFileLoader.load_data(bom_file.getvalue(), bom_file.name, skiprows=1)
            purchase_df = SecureFileLoader.load_data(purchase_file.getvalue(), purchase_file.name)
        
        if bom_df is None or purchase_df is None:
            st.error("âŒ íŒŒì¼ ë¡œë”©ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
            st.stop()
        
        # ë°ì´í„° ê²€ì¦
        bom_valid, bom_errors = DataValidator.validate_bom_schema(bom_df)
        purchase_valid, purchase_error = DataValidator.validate_purchase_data(purchase_df)
        
        if not bom_valid:
            st.error("âŒ BOM ë°ì´í„° ê²€ì¦ ì‹¤íŒ¨:")
            for error in bom_errors:
                st.error(f"  â€¢ {error}")
            st.stop()
        
        if not purchase_valid:
            st.error(f"âŒ êµ¬ë§¤ ë°ì´í„° ê²€ì¦ ì‹¤íŒ¨: {purchase_error}")
            st.stop()
        
        # ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°
        st.header("2. ğŸ“‹ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("ğŸ“‹ BOM ë°ì´í„°")
            st.info(f"ğŸ“Š **{len(bom_df):,}**í–‰ Ã— **{len(bom_df.columns)}**ì—´")
            
            if show_debug:
                st.write("**ì»¬ëŸ¼ëª…:**", list(bom_df.columns))
            
            st.dataframe(bom_df.head(), use_container_width=True)
            
        with col2:
            st.subheader("ğŸ’° êµ¬ë§¤ ë°ì´í„°")
            st.info(f"ğŸ“Š **{len(purchase_df):,}**í–‰ Ã— **{len(purchase_df.columns)}**ì—´")
            
            if show_debug:
                st.write("**ì»¬ëŸ¼ëª…:**", list(purchase_df.columns))
            
            st.dataframe(purchase_df.head(), use_container_width=True)
        
        # ì›ê°€ ê³„ì‚° ì‹¤í–‰
        st.header("3. ğŸ”¥ BOM ì›ê°€ ê³„ì‚°")
        
        if st.button("ğŸš€ ì›ê°€ ê³„ì‚° ì‹œì‘!", type="primary", use_container_width=True):
            
            # 1ë‹¨ê³„: êµ¬ë§¤ ë‹¨ê°€ ì¶”ì¶œ
            with st.spinner("ğŸ’° êµ¬ë§¤ ë‹¨ê°€ ì¶”ì¶œ ì¤‘..."):
                purchase_prices = PurchasePriceExtractor.extract_prices(purchase_df)
            
            if not purchase_prices:
                st.error("âŒ êµ¬ë§¤ ë‹¨ê°€ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                st.stop()
            
            st.success(f"âœ… êµ¬ë§¤ ë‹¨ê°€ ì¶”ì¶œ ì™„ë£Œ: **{len(purchase_prices):,}**ê°œ í’ˆëª©")
            
            if show_debug:
                st.write("**êµ¬ë§¤ ë‹¨ê°€ ìƒ˜í”Œ:**", dict(list(purchase_prices.items())[:5]))
            
            # 2ë‹¨ê³„: BOM ì›ê°€ ê³„ì‚°
            calculator = BOMCostCalculator()
            
            with st.spinner("ğŸ”„ BOM ì›ê°€ ê³„ì‚° ì¤‘..."):
                result_df, details_df = calculator.calculate_all_costs(bom_df, purchase_prices)
            
            if result_df.empty:
                st.error("âŒ BOM ì›ê°€ ê³„ì‚°ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                st.stop()
            
            # 3ë‹¨ê³„: ê²°ê³¼ ë¶„ì„ ë° í‘œì‹œ
            st.header("4. ğŸ¯ ì™„ì œí’ˆ ì›ê°€ ê³„ì‚° ê²°ê³¼")
            
            # ì™„ì œí’ˆ í•„í„°ë§
            finished_goods = result_df[
                result_df['ìƒì‚°í’ˆëª©ëª…'].str.contains('[ì™„ì œí’ˆ]', regex=False, na=False)
            ].copy()
            
            # í†µê³„ í‘œì‹œ
            total_finished = len(finished_goods)
            calculated_finished = len(finished_goods[finished_goods['ê³„ì‚°ìƒíƒœ'] == 'ê³„ì‚°ì™„ë£Œ'])
            success_rate = (calculated_finished / total_finished * 100) if total_finished > 0 else 0
            
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                st.metric("ğŸ¯ ì „ì²´ ì™„ì œí’ˆ", f"{total_finished:,}ê°œ")
            with col2:
                st.metric("âœ… ê³„ì‚° ì„±ê³µ", f"{calculated_finished:,}ê°œ")
            with col3:
                st.metric("âŒ ê³„ì‚° ì‹¤íŒ¨", f"{total_finished - calculated_finished:,}ê°œ")
            with col4:
                st.metric("ğŸ“Š ì„±ê³µë¥ ", f"{success_rate:.1f}%")
            
            # ê²°ê³¼ í…Œì´ë¸”
            if not finished_goods.empty:
                display_df = finished_goods[['ìƒì‚°í’ˆëª©ì½”ë“œ', 'ìƒì‚°í’ˆëª©ëª…', 'ê³„ì‚°ëœë‹¨ìœ„ì›ê°€', 'ê³„ì‚°ìƒíƒœ']].copy()
                display_df.columns = ['í’ˆëª©ì½”ë“œ', 'í’ˆëª©ëª…', 'ë‹¨ìœ„ì›ê°€(ì›)', 'ìƒíƒœ']
                
                # ì¡°ê±´ë¶€ ìŠ¤íƒ€ì¼ë§
                def highlight_status(row):
                    if row['ìƒíƒœ'] == 'ê³„ì‚°ì™„ë£Œ':
                        return ['background-color: #d4edda; color: #155724'] * len(row)
                    else:
                        return ['background-color: #f8d7da; color: #721c24'] * len(row)
                
                styled_df = display_df.style.apply(highlight_status, axis=1).format({
                    'ë‹¨ìœ„ì›ê°€(ì›)': '{:,.0f}'
                })
                
                st.dataframe(styled_df, use_container_width=True, height=400)
                
                # ì›ê°€ ë¶„ì„
                calculated_items = finished_goods[finished_goods['ê³„ì‚°ìƒíƒœ'] == 'ê³„ì‚°ì™„ë£Œ']
                if not calculated_items.empty:
                    avg_cost = calculated_items['ê³„ì‚°ëœë‹¨ìœ„ì›ê°€'].mean()
                    max_cost = calculated_items['ê³„ì‚°ëœë‹¨ìœ„ì›ê°€'].max()
                    min_cost = calculated_items[calculated_items['ê³„ì‚°ëœë‹¨ìœ„ì›ê°€'] > 0]['ê³„ì‚°ëœë‹¨ìœ„ì›ê°€'].min()
                    
                    st.subheader("ğŸ“ˆ ì›ê°€ ë¶„ì„ ìš”ì•½")
                    col1, col2, col3 = st.columns(3)
                    
                    with col1:
                        st.metric("ğŸ’° í‰ê·  ì›ê°€", f"{avg_cost:,.0f}ì›")
                    with col2:
                        st.metric("ğŸ“ˆ ìµœê³  ì›ê°€", f"{max_cost:,.0f}ì›")
                    with col3:
                        st.metric("ğŸ“‰ ìµœì € ì›ê°€", f"{min_cost:,.0f}ì›")
                    
                    # ìƒìœ„ ì›ê°€ ì œí’ˆ
                    top_cost_items = calculated_items.nlargest(10, 'ê³„ì‚°ëœë‹¨ìœ„ì›ê°€')
                    
                    with st.expander("ğŸ’ ì›ê°€ ìƒìœ„ 10ê°œ ì™„ì œí’ˆ", expanded=True):
                        for idx, (_, item) in enumerate(top_cost_items.iterrows(), 1):
                            st.write(f"**{idx}.** {item['ìƒì‚°í’ˆëª©ì½”ë“œ']} - **{item['ê³„ì‚°ëœë‹¨ìœ„ì›ê°€']:,.0f}ì›** - {item['ìƒì‚°í’ˆëª©ëª…']}")
                
                # ì‹œê°í™” ì°¨íŠ¸
                if show_charts and plotly_available:
                    st.header("5. ğŸ“Š ë°ì´í„° ì‹œê°í™”")
                    DataVisualizer.create_cost_analysis_charts(finished_goods)
            
            else:
                st.warning("âš ï¸ ì™„ì œí’ˆ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            
            # ê³„ì‚° ì‹¤íŒ¨ í•­ëª© ë¶„ì„
            failed_items = finished_goods[finished_goods['ê³„ì‚°ìƒíƒœ'] == 'ê³„ì‚°ë¶ˆê°€']
            if not failed_items.empty:
                with st.expander(f"âš ï¸ ê³„ì‚° ì‹¤íŒ¨ í•­ëª© {len(failed_items):,}ê°œ"):
                    st.warning("ë‹¤ìŒ ì™„ì œí’ˆë“¤ì€ êµ¬ì„± ë¶€í’ˆì˜ ì›ê°€ ì •ë³´ ë¶€ì¡±ìœ¼ë¡œ ê³„ì‚°í•  ìˆ˜ ì—†ì—ˆìŠµë‹ˆë‹¤:")
                    st.dataframe(
                        failed_items[['ìƒì‚°í’ˆëª©ì½”ë“œ', 'ìƒì‚°í’ˆëª©ëª…']], 
                        use_container_width=True
                    )
            
            # ë””ë²„ê¹… ì •ë³´
            if show_debug and hasattr(calculator, 'calculation_log'):
                with st.expander("ğŸ” ê³„ì‚° ë¡œê·¸ (ë””ë²„ê¹…ìš©)"):
                    if calculator.calculation_log:
                        debug_df = pd.DataFrame(calculator.calculation_log)
                        st.dataframe(debug_df, use_container_width=True)
                    else:
                        st.info("ê³„ì‚° ë¡œê·¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
            
            # ê²°ê³¼ ë‹¤ìš´ë¡œë“œ
            st.header("6. ğŸ“¥ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ")
            
            with st.spinner("ğŸ“Š ì—‘ì…€ íŒŒì¼ ìƒì„± ì¤‘..."):
                excel_data = ExcelExporter.export_results(finished_goods, result_df, details_df)
            
            if excel_data:
                st.download_button(
                    label="ğŸ“Š BOM ì›ê°€ ê³„ì‚° ê²°ê³¼ ë‹¤ìš´ë¡œë“œ (Excel)",
                    data=excel_data,
                    file_name=f'BOMì›ê°€ê³„ì‚°_ì•ˆì •ì„±ê°•í™”_{datetime.now().strftime("%Y%m%d_%H%M%S")}.xlsx',
                    mime='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',
                    type="primary",
                    use_container_width=True
                )
            else:
                # CSV ëŒ€ì•ˆ ì œê³µ
                csv_data = finished_goods.to_csv(index=False, encoding='utf-8-sig')
                st.download_button(
                    label="ğŸ“„ ì™„ì œí’ˆ ì›ê°€ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ (CSV)",
                    data=csv_data,
                    file_name=f'BOMì›ê°€ê³„ì‚°_{datetime.now().strftime("%Y%m%d_%H%M%S")}.csv',
                    mime='text/csv',
                    use_container_width=True
                )
            
            # ì„±ê³µ ë©”ì‹œì§€
            st.balloons()
            st.success("ğŸ‰ BOM ì›ê°€ ê³„ì‚°ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
            
            if logging_available:
                logger.info("BOM ì›ê°€ ê³„ì‚° í”„ë¡œì„¸ìŠ¤ ì™„ë£Œ")
    
    else:
        st.info("ğŸ‘† BOM ë°ì´í„°ì™€ êµ¬ë§¤ ë°ì´í„° íŒŒì¼ì„ ëª¨ë‘ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
        
        # ì‚¬ìš©ë²• ì•ˆë‚´
        with st.expander("ğŸ“– ì‚¬ìš©ë²• ì•ˆë‚´", expanded=True):
            st.markdown("""
            ### ğŸ“‹ í•„ìˆ˜ ë°ì´í„° í˜•ì‹
            
            **BOM ë°ì´í„°:**
            - `ìƒì‚°í’ˆëª©ì½”ë“œ`: ìƒì‚°í•  ì œí’ˆì˜ ì½”ë“œ
            - `ìƒì‚°í’ˆëª©ëª…`: ìƒì‚°í•  ì œí’ˆì˜ ì´ë¦„ (ì™„ì œí’ˆì€ '[ì™„ì œí’ˆ]' í¬í•¨)
            - `ì†Œëª¨í’ˆëª©ì½”ë“œ`: í•„ìš”í•œ ë¶€í’ˆ/ì›ë£Œì˜ ì½”ë“œ  
            - `ì†Œëª¨í’ˆëª©ëª…`: í•„ìš”í•œ ë¶€í’ˆ/ì›ë£Œì˜ ì´ë¦„
            - `ì†Œìš”ëŸ‰`: ì œí’ˆ 1ê°œ ìƒì‚°ì— í•„ìš”í•œ ë¶€í’ˆ ìˆ˜ëŸ‰
            
            **êµ¬ë§¤ ë°ì´í„°:**
            - `ì¼ì-No.` (ë˜ëŠ” ì¼ì): êµ¬ë§¤ ì¼ì
            - `í’ˆëª©ì½”ë“œ`: êµ¬ë§¤í•œ í’ˆëª©ì˜ ì½”ë“œ
            - `ë‹¨ê°€`: í’ˆëª©ì˜ ë‹¨ìœ„ ê°€ê²©
            
            ### âš¡ ì£¼ìš” ê¸°ëŠ¥
            - ğŸ”„ **ë‹¤ë‹¨ê³„ BOM ê³„ì‚°**: Aì œí’ˆâ†’Bì¤‘ê°„ì¬â†’Cì›ë£Œ í˜•íƒœì˜ ë³µì¡í•œ êµ¬ì¡° ì§€ì›
            - ğŸ“Š **ì‹¤ì‹œê°„ ì§„í–‰ë¥ **: ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬ ì‹œ ì§„í–‰ìƒí™© í‘œì‹œ
            - ğŸ›¡ï¸ **ë°ì´í„° ê²€ì¦**: íŒŒì¼ í˜•ì‹, ìŠ¤í‚¤ë§ˆ, ë°ì´í„° í’ˆì§ˆ ìë™ ê²€ì¦
            - ğŸ“ˆ **ì‹œê°í™” ë¶„ì„**: ì›ê°€ ë¶„í¬, ìƒìœ„ ì œí’ˆ ë“± ë‹¤ì–‘í•œ ì°¨íŠ¸ ì œê³µ
            - ğŸ“¥ **í¬ë§·íŒ…ëœ ì¶œë ¥**: ì»¬ëŸ¼ ë„ˆë¹„, ìƒ‰ìƒ, ìŠ¤íƒ€ì¼ì´ ì ìš©ëœ ì—‘ì…€ íŒŒì¼
            """)

if __name__ == "__main__":
    main()
