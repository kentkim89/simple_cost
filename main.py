"""
BOM ì›ê°€ ê³„ì‚°ê¸° - SharePoint ì—°ë™ ë²„ì „
SharePointì—ì„œ BOM ë°ì´í„°ë¥¼ ìë™ìœ¼ë¡œ ê°€ì ¸ì™€ì„œ ê³„ì‚°í•˜ëŠ” ë²„ì „
"""

import streamlit as st
import pandas as pd
import numpy as np
import io
import requests
import json
from typing import Dict, Optional, Tuple
from datetime import datetime
import time
import warnings

# ê²½ê³  í•„í„°ë§
warnings.filterwarnings('ignore')

# ì„ íƒì  import (ì—†ì–´ë„ ë™ì‘)
try:
    from tqdm import stqdm
    HAS_PROGRESS = True
except ImportError:
    HAS_PROGRESS = False

try:
    import plotly.express as px
    HAS_PLOTLY = True
except ImportError:
    HAS_PLOTLY = False

class Config:
    """ì„¤ì • í´ë˜ìŠ¤"""
    MAX_FILE_SIZE_MB = 100
    REQUIRED_BOM_COLS = ['ìƒì‚°í’ˆëª©ì½”ë“œ', 'ìƒì‚°í’ˆëª©ëª…', 'ì†Œëª¨í’ˆëª©ì½”ë“œ', 'ì†Œëª¨í’ˆëª©ëª…', 'ì†Œìš”ëŸ‰']
    TEST_ITEM_CODE = '99701'

class SharePointClient:
    """SharePoint ì—°ë™ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.access_token = None
        self.token_expires_at = 0
        
    def get_access_token(self) -> Optional[str]:
        """Azure AD í† í° íšë“"""
        try:
            # Streamlit secretsì—ì„œ ì„¤ì • ì½ê¸°
            tenant_id = st.secrets["sharepoint"]["tenant_id"]
            client_id = st.secrets["sharepoint"]["client_id"]
            client_secret = st.secrets["sharepoint"]["client_secret"]
            
            # í† í°ì´ ìœ íš¨í•œì§€ í™•ì¸ (5ë¶„ ì—¬ìœ )
            if self.access_token and time.time() < self.token_expires_at - 300:
                return self.access_token
            
            # ìƒˆ í† í° ìš”ì²­
            token_url = f"https://login.microsoftonline.com/{tenant_id}/oauth2/v2.0/token"
            
            token_data = {
                'grant_type': 'client_credentials',
                'client_id': client_id,
                'client_secret': client_secret,
                'scope': 'https://graph.microsoft.com/.default'
            }
            
            response = requests.post(token_url, data=token_data)
            response.raise_for_status()
            
            token_info = response.json()
            self.access_token = token_info['access_token']
            self.token_expires_at = time.time() + token_info.get('expires_in', 3600)
            
            st.success("ğŸ”‘ SharePoint ì¸ì¦ ì„±ê³µ!")
            return self.access_token
            
        except Exception as e:
            st.error(f"âŒ SharePoint ì¸ì¦ ì‹¤íŒ¨: {e}")
            return None
    
    def get_site_id(self, site_name: str) -> Optional[str]:
        """ì‚¬ì´íŠ¸ ID íšë“"""
        try:
            token = self.get_access_token()
            if not token:
                return None
            
            headers = {
                'Authorization': f'Bearer {token}',
                'Accept': 'application/json'
            }
            
            # ì‚¬ì´íŠ¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            site_url = f"https://graph.microsoft.com/v1.0/sites/goremi.sharepoint.com:/sites/{site_name}"
            response = requests.get(site_url, headers=headers)
            response.raise_for_status()
            
            site_info = response.json()
            return site_info['id']
            
        except Exception as e:
            st.error(f"âŒ ì‚¬ì´íŠ¸ ID íšë“ ì‹¤íŒ¨: {e}")
            return None
    
    def download_file_from_sharepoint(self, file_url: str) -> Optional[bytes]:
        """SharePoint íŒŒì¼ ë‹¤ìš´ë¡œë“œ (ê°œì„ ëœ ë²„ì „)"""
        try:
            token = self.get_access_token()
            if not token:
                return None
            
            site_name = st.secrets["sharepoint_files"]["site_name"]
            file_name = st.secrets["sharepoint_files"]["file_name"]
            
            site_id = self.get_site_id(site_name)
            if not site_id:
                return None
            
            headers = {
                'Authorization': f'Bearer {token}',
                'Accept': 'application/json'
            }
            
            st.info(f"ğŸ” íŒŒì¼ ê²€ìƒ‰ ì¤‘: {file_name}")
            
            # ë°©ë²• 1: ë“œë¼ì´ë¸Œë³„ íŒŒì¼ ê²€ìƒ‰
            drives_url = f"https://graph.microsoft.com/v1.0/sites/{site_id}/drives"
            drives_response = requests.get(drives_url, headers=headers)
            drives_response.raise_for_status()
            
            drives = drives_response.json()['value']
            if not drives:
                st.error("âŒ SharePoint ë“œë¼ì´ë¸Œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                return None
            
            file_item = None
            drive_id = None
            
            # ëª¨ë“  ë“œë¼ì´ë¸Œì—ì„œ íŒŒì¼ ê²€ìƒ‰
            for drive in drives:
                try:
                    drive_id = drive['id']
                    st.info(f"ğŸ” ë“œë¼ì´ë¸Œ '{drive['name']}'ì—ì„œ ê²€ìƒ‰ ì¤‘...")
                    
                    # ë°©ë²• 1-1: ê²€ìƒ‰ API ì‚¬ìš©
                    search_url = f"https://graph.microsoft.com/v1.0/drives/{drive_id}/root/search(q='{file_name}')"
                    search_response = requests.get(search_url, headers=headers)
                    
                    if search_response.status_code == 200:
                        search_results = search_response.json().get('value', [])
                        if search_results:
                            file_item = search_results[0]
                            st.info(f"âœ… íŒŒì¼ ë°œê²¬: {file_item['name']}")
                            break
                    
                    # ë°©ë²• 1-2: ë£¨íŠ¸ ë””ë ‰í„°ë¦¬ ì§ì ‘ ì¡°íšŒ
                    if not file_item:
                        root_url = f"https://graph.microsoft.com/v1.0/drives/{drive_id}/root/children"
                        root_response = requests.get(root_url, headers=headers)
                        
                        if root_response.status_code == 200:
                            root_files = root_response.json().get('value', [])
                            for f in root_files:
                                if f['name'].lower() == file_name.lower():
                                    file_item = f
                                    st.info(f"âœ… ë£¨íŠ¸ì—ì„œ íŒŒì¼ ë°œê²¬: {file_item['name']}")
                                    break
                    
                    if file_item:
                        break
                        
                except Exception as drive_error:
                    st.warning(f"âš ï¸ ë“œë¼ì´ë¸Œ '{drive['name']}' ê²€ìƒ‰ ì‹¤íŒ¨: {drive_error}")
                    continue
            
            if not file_item:
                st.error(f"âŒ íŒŒì¼ '{file_name}'ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                return None
            
            st.info(f"ğŸ“ íŒŒì¼ ì •ë³´: {file_item['name']} (í¬ê¸°: {file_item.get('size', 0):,} bytes)")
            
            # ë°©ë²• 2: ë‹¤ìš´ë¡œë“œ URL ìƒì„± (ì—¬ëŸ¬ ë°©ë²• ì‹œë„)
            download_url = None
            
            # ë°©ë²• 2-1: @microsoft.graph.downloadUrl ì‚¬ìš©
            if '@microsoft.graph.downloadUrl' in file_item:
                download_url = file_item['@microsoft.graph.downloadUrl']
                st.info("ğŸ”— downloadUrl ë°©ì‹ ì‚¬ìš©")
            
            # ë°©ë²• 2-2: /content ì—”ë“œí¬ì¸íŠ¸ ì‚¬ìš©
            elif 'id' in file_item:
                download_url = f"https://graph.microsoft.com/v1.0/drives/{drive_id}/items/{file_item['id']}/content"
                st.info("ğŸ”— content ì—”ë“œí¬ì¸íŠ¸ ë°©ì‹ ì‚¬ìš©")
            
            # ë°©ë²• 2-3: ì§ì ‘ ê²½ë¡œë¡œ ì ‘ê·¼
            else:
                download_url = f"https://graph.microsoft.com/v1.0/drives/{drive_id}/root:/{file_name}:/content"
                st.info("ğŸ”— ì§ì ‘ ê²½ë¡œ ë°©ì‹ ì‚¬ìš©")
            
            if not download_url:
                st.error("âŒ ë‹¤ìš´ë¡œë“œ URLì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                return None
            
            # íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì‹¤í–‰
            st.info("ğŸ“¥ íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì‹œì‘...")
            
            # content ì—”ë“œí¬ì¸íŠ¸ëŠ” Authorization í—¤ë” í•„ìš”
            if 'graph.microsoft.com' in download_url and '/content' in download_url:
                download_headers = headers.copy()
            else:
                download_headers = {}  # downloadUrlì€ ì´ë¯¸ ì¸ì¦ëœ URL
            
            file_response = requests.get(download_url, headers=download_headers)
            file_response.raise_for_status()
            
            if len(file_response.content) == 0:
                st.error("âŒ ë‹¤ìš´ë¡œë“œëœ íŒŒì¼ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤")
                return None
            
            st.success(f"âœ… íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {len(file_response.content):,} bytes")
            return file_response.content
            
        except requests.exceptions.HTTPError as e:
            st.error(f"âŒ HTTP ì˜¤ë¥˜: {e.response.status_code} - {e.response.text}")
            return None
        except Exception as e:
            st.error(f"âŒ SharePoint íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
            st.error(f"ğŸ” ë””ë²„ê·¸ ì •ë³´: {type(e).__name__}")
            return None
    
    def get_file_info(self, file_url: str) -> Optional[Dict]:
        """SharePoint íŒŒì¼ ì •ë³´ ì¡°íšŒ"""
        try:
            token = self.get_access_token()
            if not token:
                return None
            
            site_name = st.secrets["sharepoint_files"]["site_name"]
            file_name = st.secrets["sharepoint_files"]["file_name"]
            
            site_id = self.get_site_id(site_name)
            if not site_id:
                return None
            
            headers = {
                'Authorization': f'Bearer {token}',
                'Accept': 'application/json'
            }
            
            # ë“œë¼ì´ë¸Œ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            drives_url = f"https://graph.microsoft.com/v1.0/sites/{site_id}/drives"
            drives_response = requests.get(drives_url, headers=headers)
            drives_response.raise_for_status()
            
            drives = drives_response.json()['value']
            if drives:
                drive_id = drives[0]['id']
                
                # íŒŒì¼ ê²€ìƒ‰
                search_url = f"https://graph.microsoft.com/v1.0/drives/{drive_id}/root/search(q='{file_name}')"
                search_response = requests.get(search_url, headers=headers)
                search_response.raise_for_status()
                
                search_results = search_response.json()['value']
                if search_results:
                    file_item = search_results[0]
                    return {
                        'name': file_item['name'],
                        'size': file_item['size'],
                        'last_modified': file_item['lastModifiedDateTime'],
                        'created': file_item['createdDateTime']
                    }
            
            return None
            
        except Exception as e:
            st.error(f"âŒ íŒŒì¼ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return None

def validate_file_size(file_content: bytes, max_mb: int = 100) -> bool:
    """íŒŒì¼ í¬ê¸° ê²€ì¦"""
    try:
        size_mb = len(file_content) / (1024 * 1024)
        if size_mb > max_mb:
            st.error(f"âŒ íŒŒì¼ì´ ë„ˆë¬´ í½ë‹ˆë‹¤: {size_mb:.1f}MB > {max_mb}MB")
            return False
        return True
    except Exception:
        return False

def safe_load_data(file_content: bytes, file_name: str, skiprows: int = 0) -> Optional[pd.DataFrame]:
    """ì•ˆì „í•œ íŒŒì¼ ë¡œë”©"""
    try:
        file_obj = io.BytesIO(file_content)
        
        # íŒŒì¼ í˜•ì‹ë³„ ë¡œë”©
        if file_name.lower().endswith('.csv'):
            # CSV ì¸ì½”ë”© ì‹œë„
            for encoding in ['utf-8-sig', 'utf-8', 'cp949', 'euc-kr']:
                try:
                    file_obj.seek(0)
                    df = pd.read_csv(file_obj, skiprows=skiprows, encoding=encoding, dtype=str)
                    break
                except:
                    continue
            else:
                st.error("âŒ CSV íŒŒì¼ ì¸ì½”ë”©ì„ ê°ì§€í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                return None
                
        elif file_name.lower().endswith(('.xlsx', '.xls')):
            df = pd.read_excel(file_obj, skiprows=skiprows, dtype=str)
        else:
            st.error("âŒ ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹")
            return None
        
        # í—¤ë” ë¬¸ì œ í•´ê²° (êµ¬ë§¤ ë°ì´í„°ìš©)
        if 'purchase' in file_name.lower() or any('Unnamed:' in str(col) for col in df.columns):
            df = fix_purchase_data_headers(df)
        
        # ë°ì´í„° ì •ì œ
        for col in df.select_dtypes(include=['object']).columns:
            df[col] = df[col].astype(str).str.strip()
        
        # ë¹ˆ í–‰/ì—´ ì œê±°
        df = df.dropna(how='all').dropna(axis=1, how='all')
        
        return df if not df.empty else None
        
    except Exception as e:
        st.error(f"âŒ íŒŒì¼ ë¡œë”© ì‹¤íŒ¨: {e}")
        return None

def fix_purchase_data_headers(df: pd.DataFrame) -> pd.DataFrame:
    """êµ¬ë§¤ ë°ì´í„° í—¤ë” ë¬¸ì œ í•´ê²°"""
    try:
        st.info("ğŸ”§ êµ¬ë§¤ ë°ì´í„° í—¤ë” ë¬¸ì œë¥¼ ê°ì§€í–ˆìŠµë‹ˆë‹¤. ìë™ìœ¼ë¡œ ìˆ˜ì •í•©ë‹ˆë‹¤...")
        
        # ì²« ë²ˆì§¸ í–‰ì—ì„œ ì‹¤ì œ í—¤ë” ì°¾ê¸°
        potential_headers = None
        
        # 0í–‰ë¶€í„° 3í–‰ê¹Œì§€ í—¤ë” í›„ë³´ ê²€ìƒ‰
        for i in range(min(4, len(df))):
            row_values = df.iloc[i].fillna('').astype(str).tolist()
            row_text = ' '.join(row_values)
            
            # í—¤ë”ì˜ íŠ¹ì§•ì ì¸ í‚¤ì›Œë“œë“¤ í™•ì¸
            header_keywords = ['ì¼ì', 'í’ˆëª©ì½”ë“œ', 'í’ˆëª©ëª…', 'ë‹¨ê°€', 'ìˆ˜ëŸ‰', 'ê±°ë˜ì²˜']
            keyword_count = sum(1 for keyword in header_keywords if keyword in row_text)
            
            if keyword_count >= 3:  # 3ê°œ ì´ìƒì˜ í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ í—¤ë”ë¡œ íŒë‹¨
                potential_headers = row_values
                header_row_idx = i
                st.info(f"ğŸ“‹ {i}í–‰ì—ì„œ ì‹¤ì œ í—¤ë”ë¥¼ ë°œê²¬í–ˆìŠµë‹ˆë‹¤: {keyword_count}ê°œ í‚¤ì›Œë“œ ë§¤ì¹­")
                break
        
        if potential_headers:
            # í—¤ë” ì •ë¦¬ ë° ì ìš©
            cleaned_headers = []
            for header in potential_headers:
                # í—¤ë”ëª… ì •ë¦¬
                header = str(header).strip()
                if header in ['', 'nan', 'None']:
                    # ë¹ˆ í—¤ë”ëŠ” ì´ì „ í—¤ë” ê¸°ë°˜ìœ¼ë¡œ ìƒì„±
                    header = f"ì»¬ëŸ¼_{len(cleaned_headers)+1}"
                
                cleaned_headers.append(header)
            
            # ìƒˆë¡œìš´ DataFrame ìƒì„±
            new_df = df.iloc[header_row_idx + 1:].copy()  # í—¤ë” ë‹¤ìŒ í–‰ë¶€í„° ë°ì´í„°
            new_df.columns = cleaned_headers[:len(new_df.columns)]  # ì»¬ëŸ¼ ìˆ˜ë§Œí¼ë§Œ í—¤ë” ì ìš©
            new_df = new_df.reset_index(drop=True)
            
            # ë¹ˆ í–‰ ì œê±°
            new_df = new_df.dropna(how='all')
            
            st.success(f"âœ… í—¤ë” ìˆ˜ì • ì™„ë£Œ: {len(cleaned_headers)}ê°œ ì»¬ëŸ¼, {len(new_df)}í–‰ ë°ì´í„°")
            st.write("**ìˆ˜ì •ëœ í—¤ë”:**", cleaned_headers[:10])  # ì²˜ìŒ 10ê°œë§Œ í‘œì‹œ
            
            return new_df
        
        else:
            st.warning("âš ï¸ ì ì ˆí•œ í—¤ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì›ë³¸ ë°ì´í„°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            return df
        
    except Exception as e:
        st.error(f"âŒ í—¤ë” ìˆ˜ì • ì¤‘ ì˜¤ë¥˜: {e}")
        return df

def validate_bom_data(df: pd.DataFrame) -> Tuple[bool, str]:
    """BOM ë°ì´í„° ê°„ë‹¨ ê²€ì¦"""
    try:
        # í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸
        missing_cols = [col for col in Config.REQUIRED_BOM_COLS if col not in df.columns]
        if missing_cols:
            return False, f"í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: {missing_cols}"
        
        # ë°ì´í„° ì¡´ì¬ í™•ì¸
        if df.empty:
            return False, "ë°ì´í„°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤"
        
        return True, "ê²€ì¦ í†µê³¼"
        
    except Exception as e:
        return False, f"ê²€ì¦ ì˜¤ë¥˜: {e}"

def extract_purchase_prices(df: pd.DataFrame) -> Dict[str, float]:
    """êµ¬ë§¤ ë°ì´í„°ì—ì„œ ë‹¨ê°€ ì¶”ì¶œ (í—¤ë” ë¬¸ì œ í•´ê²° í¬í•¨)"""
    try:
        if df.empty:
            return {}
        
        st.write("ğŸ“Š **êµ¬ë§¤ ë°ì´í„° ë¶„ì„ ì¤‘...**")
        st.write(f"- ì›ë³¸ ì»¬ëŸ¼: {list(df.columns)[:5]}...")  # ì²˜ìŒ 5ê°œë§Œ í‘œì‹œ
        
        # ì»¬ëŸ¼ ìë™ ê°ì§€ (ê°œì„ ëœ ë²„ì „)
        date_col, item_col, price_col = None, None, None
        
        # ê° ì»¬ëŸ¼ëª…ì„ ë¶„ì„í•˜ì—¬ ë§¤ì¹­
        for col in df.columns:
            col_str = str(col).lower()
            col_original = str(col)
            
            # ì¼ì ì»¬ëŸ¼ ê°ì§€
            if not date_col:
                if any(keyword in col_str for keyword in ['ì¼ì', 'date', 'ë‚ ì§œ']) or 'ì¼ì-no' in col_str:
                    date_col = col
                    st.info(f"ğŸ“… ì¼ì ì»¬ëŸ¼ ë°œê²¬: '{col_original}'")
            
            # í’ˆëª©ì½”ë“œ ì»¬ëŸ¼ ê°ì§€  
            if not item_col:
                if 'í’ˆëª©ì½”ë“œ' in col_str:
                    item_col = col
                    st.info(f"ğŸ”– í’ˆëª©ì½”ë“œ ì»¬ëŸ¼ ë°œê²¬: '{col_original}'")
            
            # ë‹¨ê°€ ì»¬ëŸ¼ ê°ì§€
            if not price_col:
                if 'ë‹¨ê°€' in col_str and 'ê³µê¸‰' not in col_str and 'ì´' not in col_str:
                    price_col = col
                    st.info(f"ğŸ’° ë‹¨ê°€ ì»¬ëŸ¼ ë°œê²¬: '{col_original}'")
        
        # ì»¬ëŸ¼ì„ ì°¾ì§€ ëª»í•œ ê²½ìš° ì¸ë±ìŠ¤ë¡œ ëŒ€ì²´
        if not date_col and len(df.columns) > 0:
            date_col = df.columns[0]
            st.warning(f"âš ï¸ ì¼ì ì»¬ëŸ¼ì„ ìë™ ì„¤ì •: '{date_col}'")
            
        if not item_col and len(df.columns) > 1:
            item_col = df.columns[1]
            st.warning(f"âš ï¸ í’ˆëª©ì½”ë“œ ì»¬ëŸ¼ì„ ìë™ ì„¤ì •: '{item_col}'")
            
        if not price_col:
            # ë‹¨ê°€ ê´€ë ¨ ì»¬ëŸ¼ ìš°ì„  íƒìƒ‰
            for i, col in enumerate(df.columns):
                if i >= 3:  # 3ë²ˆì§¸ ì»¬ëŸ¼ë¶€í„°
                    sample_value = str(df[col].dropna().iloc[0] if not df[col].dropna().empty else '')
                    # ìˆ«ìë¡œ ë³€í™˜ ê°€ëŠ¥í•œ ì»¬ëŸ¼ ì°¾ê¸°
                    try:
                        float(sample_value.replace(',', ''))
                        price_col = col
                        st.warning(f"âš ï¸ ë‹¨ê°€ ì»¬ëŸ¼ì„ ì¶”ì • ì„¤ì •: '{col}' (ìƒ˜í”Œê°’: {sample_value})")
                        break
                    except:
                        continue
            
            # ê·¸ë˜ë„ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’
            if not price_col and len(df.columns) > 5:
                price_col = df.columns[5]
                st.warning(f"âš ï¸ ë‹¨ê°€ ì»¬ëŸ¼ì„ ê¸°ë³¸ ì„¤ì •: '{price_col}'")
        
        if not all([date_col, item_col, price_col]):
            st.error(f"âŒ í•„ìˆ˜ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì¼ì: {date_col}, í’ˆëª©ì½”ë“œ: {item_col}, ë‹¨ê°€: {price_col}")
            return {}
        
        st.success(f"âœ… ì»¬ëŸ¼ ë§¤í•‘ ì™„ë£Œ - ì¼ì: {date_col}, í’ˆëª©ì½”ë“œ: {item_col}, ë‹¨ê°€: {price_col}")
        
        # ë°ì´í„° ì •ì œ
        work_df = df[[date_col, item_col, price_col]].copy()
        work_df.columns = ['date', 'item_code', 'price']
        
        # ë¹ˆê°’ ì œê±°
        work_df = work_df.dropna()
        
        # íƒ€ì… ë³€í™˜
        work_df['item_code'] = work_df['item_code'].astype(str).str.strip()
        work_df['price'] = pd.to_numeric(work_df['price'], errors='coerce')
        
        # ìœ íš¨í•œ ë°ì´í„°ë§Œ
        work_df = work_df[
            (work_df['item_code'] != '') & 
            (work_df['item_code'] != 'nan') &
            (work_df['price'] > 0) & 
            (work_df['price'].notna())
        ]
        
        if work_df.empty:
            st.error("âŒ ìœ íš¨í•œ êµ¬ë§¤ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return {}
        
        # ë‚ ì§œ ì²˜ë¦¬ (ê°„ë‹¨í•˜ê²Œ)
        try:
            work_df['date_str'] = work_df['date'].astype(str).str.split('-').str[0]
            work_df['date_parsed'] = pd.to_datetime(work_df['date_str'], errors='coerce')
            work_df = work_df.dropna(subset=['date_parsed'])
            work_df = work_df.sort_values('date_parsed', ascending=False)
            st.info("ğŸ“… ë‚ ì§œìˆœ ì •ë ¬ ì™„ë£Œ")
        except:
            st.warning("âš ï¸ ë‚ ì§œ ì •ë ¬ ì‹¤íŒ¨, ì›ë³¸ ìˆœì„œ ìœ ì§€")
        
        # ìµœì‹  ë‹¨ê°€ ì¶”ì¶œ
        latest_prices = work_df.drop_duplicates(subset='item_code', keep='first')
        
        # ë”•ì…”ë„ˆë¦¬ ë³€í™˜
        price_dict = {}
        for _, row in latest_prices.iterrows():
            code = row['item_code']
            price = row['price']
            if pd.notna(price) and price > 0:
                price_dict[code] = float(price)
        
        st.write(f"**êµ¬ë§¤ë‹¨ê°€ ìƒ˜í”Œ (ì²˜ìŒ 5ê°œ):**")
        sample_items = list(price_dict.items())[:5]
        for code, price in sample_items:
            st.write(f"  â€¢ {code}: {price:,.0f}ì›")
        
        return price_dict
        
    except Exception as e:
        st.error(f"âŒ êµ¬ë§¤ ë‹¨ê°€ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
        return {}

def clean_bom_data(df: pd.DataFrame) -> pd.DataFrame:
    """BOM ë°ì´í„° ì •ì œ (ê²€ì¦ ì—†ì´)"""
    try:
        clean_df = df.copy()
        
        # í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸
        missing_cols = [col for col in Config.REQUIRED_BOM_COLS if col not in clean_df.columns]
        if missing_cols:
            st.error(f"âŒ í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: {missing_cols}")
            return pd.DataFrame()
        
        # ë°ì´í„° ì •ì œ - ê²€ì¦ ì „ì— íƒ€ì… ë³€í™˜
        clean_df['ìƒì‚°í’ˆëª©ì½”ë“œ'] = clean_df['ìƒì‚°í’ˆëª©ì½”ë“œ'].astype(str).str.strip()
        clean_df['ì†Œëª¨í’ˆëª©ì½”ë“œ'] = clean_df['ì†Œëª¨í’ˆëª©ì½”ë“œ'].astype(str).str.strip()
        
        # ì†Œìš”ëŸ‰ ë³€í™˜ (ë¬¸ì œì˜ í•µì‹¬)
        clean_df['ì†Œìš”ëŸ‰'] = pd.to_numeric(clean_df['ì†Œìš”ëŸ‰'], errors='coerce').fillna(0.0)
        
        # test í’ˆëª© ì œê±°
        before_count = len(clean_df)
        clean_df = clean_df[clean_df['ì†Œëª¨í’ˆëª©ì½”ë“œ'] != Config.TEST_ITEM_CODE]
        after_count = len(clean_df)
        
        if before_count != after_count:
            st.info(f"ğŸ§¹ test í’ˆëª© ì œê±°: {before_count:,} â†’ {after_count:,}í–‰")
        
        # ìœ íš¨í•˜ì§€ ì•Šì€ ë°ì´í„° ì œê±°
        clean_df = clean_df[
            (clean_df['ìƒì‚°í’ˆëª©ì½”ë“œ'] != '') &
            (clean_df['ì†Œëª¨í’ˆëª©ì½”ë“œ'] != '') &
            (clean_df['ìƒì‚°í’ˆëª©ì½”ë“œ'] != 'nan') &
            (clean_df['ì†Œëª¨í’ˆëª©ì½”ë“œ'] != 'nan') &
            (clean_df['ì†Œìš”ëŸ‰'] >= 0)
        ]
        
        return clean_df
        
    except Exception as e:
        st.error(f"âŒ BOM ë°ì´í„° ì •ì œ ì˜¤ë¥˜: {e}")
        return pd.DataFrame()

def calculate_product_cost_with_reason(product_code: str, bom_df: pd.DataFrame, all_costs: Dict[str, float], cache: Dict[str, float]) -> Tuple[float, str]:
    """ë‹¨ì¼ ì œí’ˆ ì›ê°€ ê³„ì‚° + ì‹¤íŒ¨ ì´ìœ  ë¶„ì„"""
    try:
        # ìºì‹œ í™•ì¸
        if product_code in cache:
            return cache[product_code], ""
        
        # BOM êµ¬ì„±ìš”ì†Œ ê°€ì ¸ì˜¤ê¸°
        components = bom_df[bom_df['ìƒì‚°í’ˆëª©ì½”ë“œ'] == product_code]
        
        if components.empty:
            cache[product_code] = 0.0
            return 0.0, "BOM êµ¬ì„±ìš”ì†Œ ì—†ìŒ"
        
        total_cost = 0.0
        missing_components = []
        zero_price_components = []
        invalid_quantity_components = []
        
        for _, comp in components.iterrows():
            comp_code = comp['ì†Œëª¨í’ˆëª©ì½”ë“œ']
            comp_name = comp['ì†Œëª¨í’ˆëª©ëª…']
            quantity = float(comp['ì†Œìš”ëŸ‰'])
            
            # ìˆ˜ëŸ‰ ê²€ì¦
            if quantity <= 0:
                invalid_quantity_components.append(f"{comp_name}({comp_code})")
                continue
            
            # ë¶€í’ˆ ë‹¨ê°€ ì°¾ê¸°
            if comp_code in all_costs:
                unit_price = all_costs[comp_code]
                if unit_price <= 0:
                    zero_price_components.append(f"{comp_name}({comp_code})")
                    continue
            elif comp_code in bom_df['ìƒì‚°í’ˆëª©ì½”ë“œ'].values:
                # ì¬ê·€ ê³„ì‚°
                unit_price, _ = calculate_product_cost_with_reason(comp_code, bom_df, all_costs, cache)
                if unit_price <= 0:
                    missing_components.append(f"{comp_name}({comp_code})")
                    continue
                all_costs[comp_code] = unit_price
            else:
                missing_components.append(f"{comp_name}({comp_code})")
                continue
            
            total_cost += quantity * unit_price
        
        cache[product_code] = total_cost
        
        # ì‹¤íŒ¨ ì´ìœ  ë¶„ì„
        if total_cost == 0:
            reasons = []
            if missing_components:
                reasons.append(f"ë‹¨ê°€ì •ë³´ ì—†ìŒ: {', '.join(missing_components[:3])}{'...' if len(missing_components) > 3 else ''}")
            if zero_price_components:
                reasons.append(f"ë‹¨ê°€ 0ì›: {', '.join(zero_price_components[:3])}{'...' if len(zero_price_components) > 3 else ''}")
            if invalid_quantity_components:
                reasons.append(f"ìˆ˜ëŸ‰ ì˜¤ë¥˜: {', '.join(invalid_quantity_components[:3])}{'...' if len(invalid_quantity_components) > 3 else ''}")
            
            failure_reason = " | ".join(reasons) if reasons else "ì•Œ ìˆ˜ ì—†ëŠ” ì´ìœ "
            return 0.0, failure_reason
        
        return total_cost, ""
        
    except Exception as e:
        return 0.0, f"ê³„ì‚° ì˜¤ë¥˜: {str(e)}"

def calculate_product_cost(product_code: str, bom_df: pd.DataFrame, all_costs: Dict[str, float], cache: Dict[str, float]) -> float:
    """ë‹¨ì¼ ì œí’ˆ ì›ê°€ ê³„ì‚° (í˜¸í™˜ì„± ìœ ì§€ìš©)"""
    cost, _ = calculate_product_cost_with_reason(product_code, bom_df, all_costs, cache)
    return cost

def calculate_all_bom_costs(bom_df: pd.DataFrame, purchase_prices: Dict[str, float]) -> Tuple[pd.DataFrame, pd.DataFrame]:
    """ì „ì²´ BOM ì›ê°€ ê³„ì‚°"""
    try:
        start_time = time.time()
        
        # ë°ì´í„° ì •ì œ
        clean_bom = clean_bom_data(bom_df)
        
        if clean_bom.empty:
            return pd.DataFrame(), pd.DataFrame()
        
        # ëª¨ë“  ìƒì‚°í’ˆëª©
        all_products = clean_bom[['ìƒì‚°í’ˆëª©ì½”ë“œ', 'ìƒì‚°í’ˆëª©ëª…']].drop_duplicates().reset_index(drop=True)
        
        st.info(f"ğŸ“Š ê³„ì‚° ëŒ€ìƒ: ìƒì‚°í’ˆëª© {len(all_products):,}ê°œ, êµ¬ë§¤ë‹¨ê°€ {len(purchase_prices):,}ê°œ")
        
        # ì „ì²´ ì›ê°€ ë”•ì…”ë„ˆë¦¬
        all_costs = purchase_prices.copy()
        calc_cache = {}
        failure_reasons = {}  # ì‹¤íŒ¨ ì´ìœ  ì €ì¥
        
        # ê³„ì‚° ì‹¤í–‰
        results = []
        
        if HAS_PROGRESS:
            iterator = stqdm(all_products.iterrows(), total=len(all_products), desc="BOM ì›ê°€ ê³„ì‚°")
        else:
            iterator = all_products.iterrows()
            progress_bar = st.progress(0)
        
        for idx, (_, product) in enumerate(iterator):
            product_code = product['ìƒì‚°í’ˆëª©ì½”ë“œ']
            product_name = product['ìƒì‚°í’ˆëª©ëª…']
            
            # ì›ê°€ ê³„ì‚°
            calculated_cost, failure_reason = calculate_product_cost_with_reason(
                product_code, clean_bom, all_costs, calc_cache
            )
            
            if calculated_cost == 0 and failure_reason:
                failure_reasons[product_code] = failure_reason
            
            results.append({
                'ìƒì‚°í’ˆëª©ì½”ë“œ': product_code,
                'ìƒì‚°í’ˆëª©ëª…': product_name,
                'ê³„ì‚°ëœë‹¨ìœ„ì›ê°€': calculated_cost,
                'ê³„ì‚°ìƒíƒœ': 'ê³„ì‚°ì™„ë£Œ' if calculated_cost > 0 else 'ê³„ì‚°ë¶ˆê°€',
                'ì‹¤íŒ¨ì´ìœ ': failure_reasons.get(product_code, '')
            })
            
            # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
            if not HAS_PROGRESS:
                progress_bar.progress((idx + 1) / len(all_products))
        
        if not HAS_PROGRESS:
            progress_bar.empty()
        
        # ê²°ê³¼ DataFrame
        result_df = pd.DataFrame(results)
        
        # ìƒì„¸ ë‚´ì—­
        details_df = clean_bom.copy()
        details_df['ë¶€í’ˆë‹¨ê°€'] = details_df['ì†Œëª¨í’ˆëª©ì½”ë“œ'].apply(lambda x: all_costs.get(x, 0.0))
        details_df['ë¶€í’ˆë³„ì›ê°€'] = details_df['ì†Œìš”ëŸ‰'] * details_df['ë¶€í’ˆë‹¨ê°€']
        
        elapsed = time.time() - start_time
        st.success(f"âœ… ê³„ì‚° ì™„ë£Œ! (ì†Œìš”ì‹œê°„: {elapsed:.1f}ì´ˆ)")
        
        return result_df, details_df
        
    except Exception as e:
        st.error(f"âŒ BOM ì›ê°€ ê³„ì‚° ì‹¤íŒ¨: {e}")
        return pd.DataFrame(), pd.DataFrame()

def create_simple_chart(df: pd.DataFrame) -> None:
    """ê°„ë‹¨í•œ ì°¨íŠ¸ ìƒì„±"""
    if not HAS_PLOTLY or df.empty:
        return
    
    try:
        # ê³„ì‚°ëœ ì™„ì œí’ˆë§Œ
        chart_data = df[df['ê³„ì‚°ëœë‹¨ìœ„ì›ê°€'] > 0]
        
        if len(chart_data) < 5:
            return
        
        # ìƒìœ„ 20ê°œ ì œí’ˆ ë°”ì°¨íŠ¸
        top_items = chart_data.nlargest(20, 'ê³„ì‚°ëœë‹¨ìœ„ì›ê°€')
        
        fig = px.bar(
            top_items,
            x='ê³„ì‚°ëœë‹¨ìœ„ì›ê°€',
            y='ìƒì‚°í’ˆëª©ì½”ë“œ',
            orientation='h',
            title='ì›ê°€ ìƒìœ„ 20ê°œ ì™„ì œí’ˆ',
            labels={'ê³„ì‚°ëœë‹¨ìœ„ì›ê°€': 'ì›ê°€ (ì›)', 'ìƒì‚°í’ˆëª©ì½”ë“œ': 'ì œí’ˆì½”ë“œ'}
        )
        fig.update_layout(height=500, yaxis={'categoryorder': 'total ascending'})
        st.plotly_chart(fig, use_container_width=True)
        
    except Exception:
        pass  # ì°¨íŠ¸ ì‹¤íŒ¨í•´ë„ ì§„í–‰

def auto_adjust_column_width(worksheet, df: pd.DataFrame, start_row: int = 1):
    """ì—‘ì…€ ì»¬ëŸ¼ ë„ˆë¹„ ìë™ ì¡°ì •"""
    try:
        from openpyxl.utils import get_column_letter
        
        for idx, column in enumerate(df.columns):
            column_letter = get_column_letter(idx + 1)
            
            # í—¤ë” ê¸¸ì´
            header_length = len(str(column))
            
            # ë°ì´í„° ìµœëŒ€ ê¸¸ì´
            if not df.empty:
                max_data_length = df[column].astype(str).str.len().max()
            else:
                max_data_length = 0
            
            # ìµœì  ë„ˆë¹„ ê³„ì‚° (í•œê¸€ ê³ ë ¤)
            max_length = max(header_length, max_data_length)
            
            # í•œê¸€ ë¬¸ìê°€ ë§ì€ ê²½ìš° ì¶”ê°€ ê³µê°„
            if any('\uac00' <= char <= '\ud7af' for char in str(column)):
                max_length = max_length * 1.3  # í•œê¸€ì€ 30% ë”
            
            # ìµœì†Œ/ìµœëŒ€ ë„ˆë¹„ ì œí•œ
            adjusted_width = min(max(max_length + 2, 10), 60)
            
            worksheet.column_dimensions[column_letter].width = adjusted_width
            
    except Exception as e:
        st.warning(f"ì»¬ëŸ¼ ë„ˆë¹„ ì¡°ì • ì‹¤íŒ¨: {e}")

def apply_excel_styling(worksheet, df: pd.DataFrame, sheet_title: str = ""):
    """ì—‘ì…€ ìŠ¤íƒ€ì¼ë§ ì ìš©"""
    try:
        from openpyxl.styles import PatternFill, Font, Alignment, Border, Side
        
        # ìƒ‰ìƒ ì •ì˜
        header_fill = PatternFill(start_color="366092", end_color="366092", fill_type="solid")
        title_fill = PatternFill(start_color="E8F4FD", end_color="E8F4FD", fill_type="solid")
        
        header_font = Font(color="FFFFFF", bold=True, size=11)
        title_font = Font(bold=True, size=14, color="1F4E79")
        data_font = Font(size=10)
        
        thin_border = Border(
            left=Side(style='thin'),
            right=Side(style='thin'), 
            top=Side(style='thin'),
            bottom=Side(style='thin')
        )
        
        # ì œëª© ìŠ¤íƒ€ì¼ (A1 ì…€)
        if sheet_title:
            title_cell = worksheet.cell(row=1, column=1)
            title_cell.value = sheet_title
            title_cell.font = title_font
            title_cell.fill = title_fill
            title_cell.alignment = Alignment(horizontal='center', vertical='center')
            
            # ì œëª© ì…€ ë³‘í•©
            worksheet.merge_cells(start_row=1, end_row=1, start_column=1, end_column=len(df.columns))
        
        # í—¤ë” ìŠ¤íƒ€ì¼ (2í–‰ ë˜ëŠ” 1í–‰)
        header_row = 2 if sheet_title else 1
        
        for col in range(1, len(df.columns) + 1):
            header_cell = worksheet.cell(row=header_row, column=col)
            header_cell.font = header_font
            header_cell.fill = header_fill
            header_cell.alignment = Alignment(horizontal='center', vertical='center')
            header_cell.border = thin_border
        
        # ë°ì´í„° ì˜ì—­ ìŠ¤íƒ€ì¼
        start_data_row = header_row + 1
        end_data_row = start_data_row + len(df) - 1
        
        for row in range(start_data_row, end_data_row + 1):
            for col in range(1, len(df.columns) + 1):
                cell = worksheet.cell(row=row, column=col)
                cell.font = data_font
                cell.border = thin_border
                cell.alignment = Alignment(vertical='center')
                
                # ìˆ«ì ì»¬ëŸ¼ ìš°ì¸¡ ì •ë ¬
                column_name = df.columns[col-1]
                if 'ì›ê°€' in column_name or 'ë‹¨ê°€' in column_name or 'ìˆ˜ëŸ‰' in column_name:
                    cell.alignment = Alignment(horizontal='right', vertical='center')
                    
                    # ìˆ«ì í¬ë§·
                    if isinstance(cell.value, (int, float)) and cell.value != 0:
                        cell.number_format = '#,##0'
        
        # í–‰ ë†’ì´ ì¡°ì •
        worksheet.row_dimensions[header_row].height = 25
        for row in range(start_data_row, end_data_row + 1):
            worksheet.row_dimensions[row].height = 20
            
    except Exception as e:
        st.warning(f"ìŠ¤íƒ€ì¼ ì ìš© ì‹¤íŒ¨: {e}")

def export_to_excel(finished_goods: pd.DataFrame, all_results: pd.DataFrame, details: pd.DataFrame) -> bytes:
    """í–¥ìƒëœ ì—‘ì…€ ë‚´ë³´ë‚´ê¸° (ìë™ ì»¬ëŸ¼ ì¡°ì • + ìŠ¤íƒ€ì¼ë§)"""
    try:
        output = io.BytesIO()
        
        with pd.ExcelWriter(output, engine='openpyxl') as writer:
            # 1. ì™„ì œí’ˆ ì›ê°€ ì‹œíŠ¸
            finished_display = finished_goods.copy()
            
            # ì‹¤íŒ¨ ì´ìœ ê°€ ìˆëŠ” ê²½ìš° ì»¬ëŸ¼ëª… ë³€ê²½
            if 'ì‹¤íŒ¨ì´ìœ ' in finished_display.columns:
                finished_display = finished_display[['ìƒì‚°í’ˆëª©ì½”ë“œ', 'ìƒì‚°í’ˆëª©ëª…', 'ê³„ì‚°ëœë‹¨ìœ„ì›ê°€', 'ê³„ì‚°ìƒíƒœ', 'ì‹¤íŒ¨ì´ìœ ']]
                finished_display.columns = ['í’ˆëª©ì½”ë“œ', 'í’ˆëª©ëª…', 'ë‹¨ìœ„ì›ê°€(ì›)', 'ê³„ì‚°ìƒíƒœ', 'ì‹¤íŒ¨ì´ìœ ']
            else:
                finished_display = finished_display[['ìƒì‚°í’ˆëª©ì½”ë“œ', 'ìƒì‚°í’ˆëª©ëª…', 'ê³„ì‚°ëœë‹¨ìœ„ì›ê°€', 'ê³„ì‚°ìƒíƒœ']]
                finished_display.columns = ['í’ˆëª©ì½”ë“œ', 'í’ˆëª©ëª…', 'ë‹¨ìœ„ì›ê°€(ì›)', 'ê³„ì‚°ìƒíƒœ']
            
            # ë°ì´í„° ì“°ê¸° (ì œëª©ìš© ê³µê°„ í™•ë³´)
            finished_display.to_excel(writer, sheet_name='ì™„ì œí’ˆì›ê°€', index=False, startrow=1)
            
            # 2. ì „ì²´ ì œí’ˆ ì›ê°€ ì‹œíŠ¸
            all_display = all_results.copy()
            if 'ì‹¤íŒ¨ì´ìœ ' in all_display.columns:
                all_display = all_display[['ìƒì‚°í’ˆëª©ì½”ë“œ', 'ìƒì‚°í’ˆëª©ëª…', 'ê³„ì‚°ëœë‹¨ìœ„ì›ê°€', 'ê³„ì‚°ìƒíƒœ', 'ì‹¤íŒ¨ì´ìœ ']]
                all_display.columns = ['í’ˆëª©ì½”ë“œ', 'í’ˆëª©ëª…', 'ë‹¨ìœ„ì›ê°€(ì›)', 'ê³„ì‚°ìƒíƒœ', 'ì‹¤íŒ¨ì´ìœ ']
            
            all_display.to_excel(writer, sheet_name='ì „ì²´ì œí’ˆì›ê°€', index=False, startrow=1)
            
            # 3. ìƒì„¸ ë‚´ì—­ ì‹œíŠ¸
            details_display = details.copy()
            details_cols = ['ìƒì‚°í’ˆëª©ì½”ë“œ', 'ìƒì‚°í’ˆëª©ëª…', 'ì†Œëª¨í’ˆëª©ì½”ë“œ', 'ì†Œëª¨í’ˆëª©ëª…', 'ì†Œìš”ëŸ‰', 'ë¶€í’ˆë‹¨ê°€', 'ë¶€í’ˆë³„ì›ê°€']
            details_display = details_display[details_cols]
            details_display.columns = ['ìƒì‚°í’ˆëª©ì½”ë“œ', 'ìƒì‚°í’ˆëª©ëª…', 'ë¶€í’ˆì½”ë“œ', 'ë¶€í’ˆëª…', 'ì†Œìš”ëŸ‰', 'ë¶€í’ˆë‹¨ê°€(ì›)', 'ë¶€í’ˆì›ê°€(ì›)']
            
            details_display.to_excel(writer, sheet_name='ìƒì„¸ë‚´ì—­', index=False, startrow=1)
            
            # ê° ì‹œíŠ¸ì— ìŠ¤íƒ€ì¼ë§ ì ìš©
            worksheets = [
                (writer.sheets['ì™„ì œí’ˆì›ê°€'], finished_display, 'ì™„ì œí’ˆ BOM ì›ê°€ ê³„ì‚° ê²°ê³¼'),
                (writer.sheets['ì „ì²´ì œí’ˆì›ê°€'], all_display, 'ì „ì²´ ì œí’ˆ ì›ê°€ ê³„ì‚° ê²°ê³¼'),
                (writer.sheets['ìƒì„¸ë‚´ì—­'], details_display, 'BOM êµ¬ì„±ìš”ì†Œë³„ ìƒì„¸ ì›ê°€ ë‚´ì—­')
            ]
            
            for worksheet, df_data, title in worksheets:
                # ì»¬ëŸ¼ ë„ˆë¹„ ìë™ ì¡°ì •
                auto_adjust_column_width(worksheet, df_data, start_row=2)
                
                # ìŠ¤íƒ€ì¼ë§ ì ìš©
                apply_excel_styling(worksheet, df_data, title)
        
        return output.getvalue()
        
    except Exception as e:
        st.error(f"âŒ ì—‘ì…€ ìƒì„± ì˜¤ë¥˜: {e}")
        return b''

def main():
    """ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜"""
    
    st.set_page_config(
        page_title="BOM ì›ê°€ ê³„ì‚°ê¸°",
        page_icon="ğŸ­",
        layout="wide"
    )
    
    st.title("ğŸ­ BOM ì›ê°€ ê³„ì‚°ê¸° (SharePoint ì—°ë™ ë²„ì „)")
    st.markdown("**ğŸ”— SharePointì—ì„œ BOM ë°ì´í„°ë¥¼ ìë™ìœ¼ë¡œ ê°€ì ¸ì™€ ê³„ì‚°í•˜ëŠ” ë²„ì „**")
    
    # ê¸°ëŠ¥ ìƒíƒœ í‘œì‹œ
    with st.sidebar:
        st.header("ğŸ“Š ì‹œìŠ¤í…œ ìƒíƒœ")
        st.info(f"""
        **í™œì„±í™”ëœ ê¸°ëŠ¥:**
        - SharePoint ì—°ë™: âœ…
        - ì§„í–‰ë¥  í‘œì‹œ: {'âœ…' if HAS_PROGRESS else 'âŒ'}
        - ì‹œê°í™”: {'âœ…' if HAS_PLOTLY else 'âŒ'}
        """)
        
        # SharePoint ì„¤ì • í™•ì¸
        try:
            tenant_id = st.secrets["sharepoint"]["tenant_id"]
            st.success("ğŸ”‘ SharePoint ì„¤ì • í™•ì¸ë¨")
        except:
            st.error("âŒ SharePoint ì„¤ì •ì´ ì—†ìŠµë‹ˆë‹¤")
    
    # SharePoint í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
    sharepoint_client = SharePointClient()
    
    # íŒŒì¼ ì—…ë¡œë“œ ë° SharePoint ë°ì´í„° ë¡œë”©
    st.header("1. ğŸ“ ë°ì´í„° ì†ŒìŠ¤")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("ğŸ“‹ BOM ë°ì´í„° (SharePoint)")
        
        # SharePoint íŒŒì¼ ì •ë³´ í‘œì‹œ
        if st.button("ğŸ” SharePoint BOM íŒŒì¼ í™•ì¸", type="secondary"):
            with st.spinner("SharePoint ì—°ê²° ì¤‘..."):
                file_url = st.secrets["sharepoint_files"]["bom_file_url"]
                file_info = sharepoint_client.get_file_info(file_url)
                
                if file_info:
                    st.success("âœ… SharePoint íŒŒì¼ í™•ì¸ ì™„ë£Œ!")
                    st.info(f"""
                    **íŒŒì¼ ì •ë³´:**
                    - íŒŒì¼ëª…: {file_info['name']}
                    - í¬ê¸°: {file_info['size']:,} bytes
                    - ìˆ˜ì •ì¼: {file_info['last_modified'][:19]}
                    """)
                else:
                    st.error("âŒ SharePoint íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        
        # ë””ë²„ê·¸ ëª¨ë“œ ì¶”ê°€
        debug_mode = st.checkbox("ğŸ”§ ë””ë²„ê·¸ ëª¨ë“œ í™œì„±í™”")
        
        if debug_mode:
            st.subheader("ğŸ” SharePoint ì—°ê²° ë””ë²„ê¹…")
            
            if st.button("ğŸ—‚ï¸ ì‚¬ì´íŠ¸ ë“œë¼ì´ë¸Œ ëª©ë¡ ë³´ê¸°"):
                with st.spinner("ë“œë¼ì´ë¸Œ ì •ë³´ ì¡°íšŒ ì¤‘..."):
                    token = sharepoint_client.get_access_token()
                    if token:
                        site_name = st.secrets["sharepoint_files"]["site_name"]
                        site_id = sharepoint_client.get_site_id(site_name)
                        
                        if site_id:
                            headers = {'Authorization': f'Bearer {token}', 'Accept': 'application/json'}
                            drives_url = f"https://graph.microsoft.com/v1.0/sites/{site_id}/drives"
                            
                            try:
                                drives_response = requests.get(drives_url, headers=headers)
                                drives_response.raise_for_status()
                                drives = drives_response.json()['value']
                                
                                st.write("**ë°œê²¬ëœ ë“œë¼ì´ë¸Œ:**")
                                for i, drive in enumerate(drives):
                                    st.write(f"{i+1}. {drive.get('name', 'Unnamed')} (ID: {drive['id']})")
                                    st.write(f"   - Type: {drive.get('driveType', 'Unknown')}")
                                    st.write(f"   - Owner: {drive.get('owner', {}).get('user', {}).get('displayName', 'Unknown')}")
                                
                            except Exception as e:
                                st.error(f"ë“œë¼ì´ë¸Œ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            
            if st.button("ğŸ“ íŒŒì¼ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸"):
                with st.spinner("íŒŒì¼ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ ì¤‘..."):
                    token = sharepoint_client.get_access_token()
                    if token:
                        site_name = st.secrets["sharepoint_files"]["site_name"]
                        file_name = st.secrets["sharepoint_files"]["file_name"]
                        site_id = sharepoint_client.get_site_id(site_name)
                        
                        if site_id:
                            headers = {'Authorization': f'Bearer {token}', 'Accept': 'application/json'}
                            drives_url = f"https://graph.microsoft.com/v1.0/sites/{site_id}/drives"
                            drives_response = requests.get(drives_url, headers=headers)
                            drives = drives_response.json()['value']
                            
                            for drive in drives:
                                drive_id = drive['id']
                                st.write(f"**ë“œë¼ì´ë¸Œ '{drive['name']}'ì—ì„œ ê²€ìƒ‰:**")
                                
                                # ê²€ìƒ‰ ë°©ë²• 1: Search API
                                try:
                                    search_url = f"https://graph.microsoft.com/v1.0/drives/{drive_id}/root/search(q='{file_name}')"
                                    search_response = requests.get(search_url, headers=headers)
                                    if search_response.status_code == 200:
                                        results = search_response.json().get('value', [])
                                        st.write(f"  - Search API: {len(results)}ê°œ ê²°ê³¼")
                                        for r in results[:3]:  # ì²˜ìŒ 3ê°œë§Œ
                                            st.write(f"    * {r['name']} ({r.get('size', 0)} bytes)")
                                except Exception as e:
                                    st.write(f"  - Search API ì‹¤íŒ¨: {e}")
                                
                                # ê²€ìƒ‰ ë°©ë²• 2: Root ë””ë ‰í„°ë¦¬
                                try:
                                    root_url = f"https://graph.microsoft.com/v1.0/drives/{drive_id}/root/children"
                                    root_response = requests.get(root_url, headers=headers)
                                    if root_response.status_code == 200:
                                        files = root_response.json().get('value', [])
                                        matching_files = [f for f in files if file_name.lower() in f['name'].lower()]
                                        st.write(f"  - Root ë””ë ‰í„°ë¦¬: ì „ì²´ {len(files)}ê°œ íŒŒì¼, ì¼ì¹˜ {len(matching_files)}ê°œ")
                                        for f in matching_files:
                                            st.write(f"    * {f['name']} ({f.get('size', 0)} bytes)")
                                except Exception as e:
                                    st.write(f"  - Root ë””ë ‰í„°ë¦¬ ì‹¤íŒ¨: {e}")
        
        # BOM ë°ì´í„° ë¡œë”© ë²„íŠ¼
        if st.button("ğŸ“¥ SharePointì—ì„œ BOM ë°ì´í„° ê°€ì ¸ì˜¤ê¸°", type="primary"):
            with st.spinner("SharePointì—ì„œ BOM ë°ì´í„° ë‹¤ìš´ë¡œë“œ ì¤‘..."):
                file_url = st.secrets["sharepoint_files"]["bom_file_url"]
                bom_content = sharepoint_client.download_file_from_sharepoint(file_url)
                
                if bom_content and validate_file_size(bom_content):
                    # ì„¸ì…˜ ìƒíƒœì— ì €ì¥
                    st.session_state['bom_content'] = bom_content
                    st.session_state['bom_filename'] = st.secrets["sharepoint_files"]["file_name"]
                    st.success("âœ… BOM ë°ì´í„° ë¡œë”© ì™„ë£Œ!")
                else:
                    st.error("âŒ BOM ë°ì´í„° ë¡œë”© ì‹¤íŒ¨")
        
        # ë¡œë”©ëœ BOM ë°ì´í„° í‘œì‹œ
        if 'bom_content' in st.session_state:
            st.success(f"ğŸ“‹ BOM ë°ì´í„° ì¤€ë¹„ë¨: {st.session_state['bom_filename']}")
    
    with col2:
        st.subheader("ğŸ’° êµ¬ë§¤ ë°ì´í„° (íŒŒì¼ ì—…ë¡œë“œ)")
        purchase_file = st.file_uploader("ğŸ’° êµ¬ë§¤ ë°ì´í„° íŒŒì¼", type=['csv', 'xlsx', 'xls'], key="purchase")
    
    # ë°ì´í„° ì²˜ë¦¬ ë° ê³„ì‚°
    if 'bom_content' in st.session_state and purchase_file:
        
        # íŒŒì¼ í¬ê¸° í™•ì¸
        if not validate_file_size(purchase_file):
            st.stop()
        
        # íŒŒì¼ ë¡œë”©
        with st.spinner("ğŸ“– ë°ì´í„° ë¡œë”© ì¤‘..."):
            # BOM ë°ì´í„° (SharePoint)
            bom_df = safe_load_data(
                st.session_state['bom_content'], 
                st.session_state['bom_filename'], 
                skiprows=1
            )
            
            # êµ¬ë§¤ ë°ì´í„° (íŒŒì¼ ì—…ë¡œë“œ)
            purchase_df = safe_load_data(purchase_file.getvalue(), purchase_file.name)
        
        if bom_df is None or purchase_df is None:
            st.stop()
        
        # ê°„ë‹¨í•œ ê²€ì¦
        bom_valid, bom_msg = validate_bom_data(bom_df)
        if not bom_valid:
            st.error(f"âŒ BOM ë°ì´í„° ì˜¤ë¥˜: {bom_msg}")
            st.stop()
        
        # ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°
        st.header("2. ğŸ“‹ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("ğŸ“‹ BOM ë°ì´í„° (SharePoint)")
            st.info(f"ğŸ“Š {len(bom_df):,}í–‰ Ã— {len(bom_df.columns)}ì—´")
            st.dataframe(bom_df.head(3), use_container_width=True)
            
        with col2:
            st.subheader("ğŸ’° êµ¬ë§¤ ë°ì´í„°")
            st.info(f"ğŸ“Š {len(purchase_df):,}í–‰ Ã— {len(purchase_df.columns)}ì—´")
            st.dataframe(purchase_df.head(3), use_container_width=True)
        
        # ì›ê°€ ê³„ì‚°
        st.header("3. ğŸš€ BOM ì›ê°€ ê³„ì‚°")
        
        if st.button("ğŸ’ª ì›ê°€ ê³„ì‚° ì‹œì‘!", type="primary", use_container_width=True):
            
            # êµ¬ë§¤ ë‹¨ê°€ ì¶”ì¶œ
            with st.spinner("ğŸ’° êµ¬ë§¤ ë‹¨ê°€ ì¶”ì¶œ ì¤‘..."):
                purchase_prices = extract_purchase_prices(purchase_df)
            
            if not purchase_prices:
                st.error("âŒ êµ¬ë§¤ ë‹¨ê°€ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                st.stop()
            
            st.success(f"âœ… êµ¬ë§¤ ë‹¨ê°€ ì¶”ì¶œ ì™„ë£Œ: {len(purchase_prices):,}ê°œ í’ˆëª©")
            
            # BOM ì›ê°€ ê³„ì‚°
            result_df, details_df = calculate_all_bom_costs(bom_df, purchase_prices)
            
            if result_df.empty:
                st.error("âŒ BOM ì›ê°€ ê³„ì‚° ì‹¤íŒ¨")
                st.stop()
            
            # ì™„ì œí’ˆ í•„í„°ë§
            finished_goods = result_df[
                result_df['ìƒì‚°í’ˆëª©ëª…'].str.contains('[ì™„ì œí’ˆ]', regex=False, na=False)
            ].copy()
            
            # ê²°ê³¼ í‘œì‹œ
            st.header("4. ğŸ¯ ì™„ì œí’ˆ ì›ê°€ ê²°ê³¼")
            
            # í†µê³„
            total = len(finished_goods)
            calculated = len(finished_goods[finished_goods['ê³„ì‚°ìƒíƒœ'] == 'ê³„ì‚°ì™„ë£Œ'])
            success_rate = (calculated / total * 100) if total > 0 else 0
            
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("ğŸ¯ ì „ì²´ ì™„ì œí’ˆ", f"{total:,}ê°œ")
            with col2:
                st.metric("âœ… ê³„ì‚° ì„±ê³µ", f"{calculated:,}ê°œ")
            with col3:
                st.metric("ğŸ“Š ì„±ê³µë¥ ", f"{success_rate:.1f}%")
            
            # ê²°ê³¼ í…Œì´ë¸”
            if not finished_goods.empty:
                # ì‹¤íŒ¨ ì´ìœ  í¬í•¨í•œ ì»¬ëŸ¼ êµ¬ì„±
                if 'ì‹¤íŒ¨ì´ìœ ' in finished_goods.columns:
                    display_df = finished_goods[['ìƒì‚°í’ˆëª©ì½”ë“œ', 'ìƒì‚°í’ˆëª©ëª…', 'ê³„ì‚°ëœë‹¨ìœ„ì›ê°€', 'ê³„ì‚°ìƒíƒœ', 'ì‹¤íŒ¨ì´ìœ ']].copy()
                    display_df.columns = ['í’ˆëª©ì½”ë“œ', 'í’ˆëª©ëª…', 'ë‹¨ìœ„ì›ê°€(ì›)', 'ìƒíƒœ', 'ì‹¤íŒ¨ì´ìœ ']
                else:
                    display_df = finished_goods[['ìƒì‚°í’ˆëª©ì½”ë“œ', 'ìƒì‚°í’ˆëª©ëª…', 'ê³„ì‚°ëœë‹¨ìœ„ì›ê°€', 'ê³„ì‚°ìƒíƒœ']].copy()
                    display_df.columns = ['í’ˆëª©ì½”ë“œ', 'í’ˆëª©ëª…', 'ë‹¨ìœ„ì›ê°€(ì›)', 'ìƒíƒœ']
                
                # ìŠ¤íƒ€ì¼ë§
                def highlight_rows(row):
                    if row['ìƒíƒœ'] == 'ê³„ì‚°ì™„ë£Œ':
                        return ['background-color: #d4edda'] * len(row)
                    else:
                        return ['background-color: #f8d7da'] * len(row)
                
                styled_df = display_df.style.apply(highlight_rows, axis=1).format({
                    'ë‹¨ìœ„ì›ê°€(ì›)': '{:,.0f}'
                })
                
                st.dataframe(styled_df, use_container_width=True, height=400)
                
                # ì‹¤íŒ¨ ì´ìœ  ë¶„ì„ ìš”ì•½
                failed_items = finished_goods[finished_goods['ê³„ì‚°ìƒíƒœ'] == 'ê³„ì‚°ë¶ˆê°€']
                if not failed_items.empty and 'ì‹¤íŒ¨ì´ìœ ' in failed_items.columns:
                    st.subheader("âš ï¸ ê³„ì‚° ì‹¤íŒ¨ ì›ì¸ ë¶„ì„")
                    
                    # ì‹¤íŒ¨ ì´ìœ ë³„ í†µê³„
                    failure_stats = {}
                    for _, item in failed_items.iterrows():
                        reasons = item['ì‹¤íŒ¨ì´ìœ '].split(' | ')
                        for reason in reasons:
                            main_reason = reason.split(':')[0] if ':' in reason else reason
                            failure_stats[main_reason] = failure_stats.get(main_reason, 0) + 1
                    
                    col1, col2 = st.columns(2)
                    with col1:
                        st.write("**ì‹¤íŒ¨ ì›ì¸ë³„ ì œí’ˆ ìˆ˜:**")
                        for reason, count in failure_stats.items():
                            st.write(f"â€¢ {reason}: {count}ê°œ")
                    
                    with col2:
                        st.write("**ì£¼ìš” ê°œì„  ë°©í–¥:**")
                        if 'ë‹¨ê°€ì •ë³´ ì—†ìŒ' in failure_stats:
                            st.write("â€¢ êµ¬ë§¤ ë°ì´í„°ì— ëˆ„ë½ëœ í’ˆëª©ì˜ ë‹¨ê°€ ì •ë³´ ë³´ì™„ í•„ìš”")
                        if 'ë‹¨ê°€ 0ì›' in failure_stats:
                            st.write("â€¢ ë‹¨ê°€ê°€ 0ì›ì¸ í’ˆëª©ì˜ ì •í™•í•œ ë‹¨ê°€ ì…ë ¥ í•„ìš”")
                        if 'ìˆ˜ëŸ‰ ì˜¤ë¥˜' in failure_stats:
                            st.write("â€¢ BOM ë°ì´í„°ì˜ ì†Œìš”ëŸ‰ ì •ë³´ ê²€í†  ë° ìˆ˜ì • í•„ìš”")
                
                # ì›ê°€ ë¶„ì„
                calculated_items = finished_goods[finished_goods['ê³„ì‚°ìƒíƒœ'] == 'ê³„ì‚°ì™„ë£Œ']
                if not calculated_items.empty and len(calculated_items) > 0:
                    avg_cost = calculated_items['ê³„ì‚°ëœë‹¨ìœ„ì›ê°€'].mean()
                    max_cost = calculated_items['ê³„ì‚°ëœë‹¨ìœ„ì›ê°€'].max()
                    min_cost = calculated_items[calculated_items['ê³„ì‚°ëœë‹¨ìœ„ì›ê°€'] > 0]['ê³„ì‚°ëœë‹¨ìœ„ì›ê°€'].min()
                    
                    st.subheader("ğŸ“ˆ ì›ê°€ í†µê³„")
                    col1, col2, col3 = st.columns(3)
                    
                    with col1:
                        st.metric("ğŸ’° í‰ê·  ì›ê°€", f"{avg_cost:,.0f}ì›")
                    with col2:
                        st.metric("ğŸ“ˆ ìµœê³  ì›ê°€", f"{max_cost:,.0f}ì›")
                    with col3:
                        st.metric("ğŸ“‰ ìµœì € ì›ê°€", f"{min_cost:,.0f}ì›")
                
                # ê°„ë‹¨í•œ ì°¨íŠ¸
                if HAS_PLOTLY:
                    st.subheader("ğŸ“Š ì›ê°€ ë¶„ì„ ì°¨íŠ¸")
                    create_simple_chart(calculated_items)
            
            else:
                st.warning("âš ï¸ ì™„ì œí’ˆ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            
            # ê³„ì‚° ì‹¤íŒ¨ í•­ëª©
            failed_items = finished_goods[finished_goods['ê³„ì‚°ìƒíƒœ'] == 'ê³„ì‚°ë¶ˆê°€']
            if not failed_items.empty:
                with st.expander(f"âš ï¸ ê³„ì‚° ì‹¤íŒ¨ {len(failed_items):,}ê°œ í•­ëª©"):
                    st.dataframe(failed_items[['ìƒì‚°í’ˆëª©ì½”ë“œ', 'ìƒì‚°í’ˆëª©ëª…']], use_container_width=True)
            
            # ê²°ê³¼ ë‹¤ìš´ë¡œë“œ
            st.header("5. ğŸ“¥ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ")
            
            excel_data = export_to_excel(finished_goods, result_df, details_df)
            
            if excel_data:
                st.download_button(
                    label="ğŸ“Š BOM ì›ê°€ ê³„ì‚° ê²°ê³¼ ë‹¤ìš´ë¡œë“œ (Excel)",
                    data=excel_data,
                    file_name=f'BOMì›ê°€ê³„ì‚°_SharePoint_{datetime.now().strftime("%Y%m%d_%H%M")}.xlsx',
                    mime='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',
                    use_container_width=True
                )
            else:
                # CSV ëŒ€ì•ˆ
                csv_data = finished_goods.to_csv(index=False, encoding='utf-8-sig')
                st.download_button(
                    label="ğŸ“„ ì™„ì œí’ˆ ì›ê°€ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ (CSV)",
                    data=csv_data,
                    file_name=f'BOMì›ê°€ê³„ì‚°_SharePoint_{datetime.now().strftime("%Y%m%d_%H%M")}.csv',
                    mime='text/csv',
                    use_container_width=True
                )
            
            st.balloons()
            st.success("ğŸ‰ BOM ì›ê°€ ê³„ì‚° ì™„ë£Œ!")
    
    else:
        st.info("ğŸ‘† SharePointì—ì„œ BOM ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ê³ , êµ¬ë§¤ ë°ì´í„° íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
        
        # ê°„ë‹¨í•œ ì‚¬ìš©ë²•
        with st.expander("ğŸ“– ì‚¬ìš©ë²•", expanded=True):
            st.markdown("""
            ### ğŸ”— SharePoint ì—°ë™ ë°©ì‹
            
            **1. BOM ë°ì´í„° (SharePoint ìë™ ì—°ë™):**
            - Azure AD ì•± ë“±ë¡ ë° ê¶Œí•œ ì„¤ì • ì™„ë£Œ
            - SharePoint íŒŒì¼ì„ ìë™ìœ¼ë¡œ ê°€ì ¸ì˜´
            - í•„ìˆ˜ ì»¬ëŸ¼: ìƒì‚°í’ˆëª©ì½”ë“œ, ìƒì‚°í’ˆëª©ëª…, ì†Œëª¨í’ˆëª©ì½”ë“œ, ì†Œëª¨í’ˆëª©ëª…, ì†Œìš”ëŸ‰
            
            **2. êµ¬ë§¤ ë°ì´í„° (íŒŒì¼ ì—…ë¡œë“œ):**
            - CSV, Excel íŒŒì¼ ì§€ì›
            - ìë™ í—¤ë” ê°ì§€ (ì¼ì, í’ˆëª©ì½”ë“œ, ë‹¨ê°€)
            
            ### âš¡ ì£¼ìš” íŠ¹ì§•
            - ğŸ”— **SharePoint ì—°ë™**: BOM ë°ì´í„° ì‹¤ì‹œê°„ ë™ê¸°í™”
            - ğŸ›¡ï¸ **Azure AD ì¸ì¦**: ì•ˆì „í•œ ë°ì´í„° ì ‘ê·¼
            - ğŸ¯ **ìë™í™”**: ìˆ˜ë™ ì—…ë¡œë“œ ì—†ì´ ìµœì‹  ë°ì´í„° í™œìš©
            - ğŸ“Š **ì‹¤ì‹œê°„ ë¶„ì„**: ì§„í–‰ë¥  ë° ê²°ê³¼ ì‹œê°í™”
            
            ### ğŸ” í•„ìˆ˜ ì„¤ì • (Streamlit Secrets)
            - SharePoint í…Œë„ŒíŠ¸, í´ë¼ì´ì–¸íŠ¸ ID/Secret
            - Azure AD API ê¶Œí•œ: Files.Read.All, Sites.Read.All
            """)

if __name__ == "__main__":
    main()
